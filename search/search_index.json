{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"dev/Languages/javascript/","text":"Javascript Simple but fairly comprehensive cheatsheet of main javascript syntax and features. Variables Initialization let a = 5; const b = \"Hello\"; Data Types let string = \"Hello\" let number = 123 let floatNumber = 3.14 # same type as number, difference only in the assignment let boolean = true, false let array = [1, 2, 3] let object = { key: \"value\" } let notAssigned = Undefined # declared but has not yet been assigned a value let nullvalue = Null # representation of no value, explicitly assigned Arrays Declaration and Initialization let arr = [1, 2, 3]; Common Methods arr.push(4); // [1, 2, 3, 4] arr.pop(); // [1, 2, 3] arr.shift(); // [2, 3] arr.unshift(1); // [1, 2, 3] arr.indexOf(2); // 1 arr.includes(3); // true Iteration arr.forEach((item) => { console.log(item); }); let newArr = arr.map((item) => item * 2); Objects Declaration and Initialization let obj = { key1: \"value1\", key2: 2, key3: function() { return \"value3\"; } }; Accessing Properties console.log(obj.key1); // \"value1\" console.log(obj[\"key2\"]); // 2 Adding/Modifying Properties obj.key4 = \"value4\"; obj[\"key5\"] = 5; Deleting Properties delete obj.key1; Conditional Statements if (condition) { // code block } else if (anotherCondition) { // code block } else { // code block } Error Handling try { // code that may throw an error } catch (error) { console.error(error.message); } finally { // code to be executed regardless of error } Switch Statement switch (expression) { case x: // code block break; case y: // code block break; default: // code block } Loops For for (let i = 0; i < 5; i++) { console.log(i); } While let i = 0; while (i < 5) { console.log(i); i++; } Do-While let i = 0; do { console.log(i); i++; } while (i < 5); Functions # Function Declaration function myFunction(a, b) { return a + b; } # Function Expression const myFunction = function(a, b) { return a + b; }; # Arrow Function const myFunction = (a, b) => a + b; Async/Await async function fetchData() { try { let response = await fetch('https://api.example.com/data'); let data = await response.json(); console.log(data); } catch (error) { console.error('Error:', error); } } Promises let promise = new Promise((resolve, reject) => { let success = true; if (success) { resolve(\"Success!\"); } else { reject(\"Error!\"); } }); promise.then((message) => { console.log(message); }).catch((error) => { console.log(error); }); Modules Importing import { myVariable, myFunction } from './myModule.js'; import myDefaultFunction from './myModule.js'; Exporting export const myVariable = 10; export function myFunction() { // function code } export default function() { // default function code }","title":"Javascript"},{"location":"dev/Languages/javascript/#javascript","text":"Simple but fairly comprehensive cheatsheet of main javascript syntax and features.","title":"Javascript"},{"location":"dev/Languages/javascript/#variables-initialization","text":"let a = 5; const b = \"Hello\";","title":"Variables Initialization"},{"location":"dev/Languages/javascript/#data-types","text":"let string = \"Hello\" let number = 123 let floatNumber = 3.14 # same type as number, difference only in the assignment let boolean = true, false let array = [1, 2, 3] let object = { key: \"value\" } let notAssigned = Undefined # declared but has not yet been assigned a value let nullvalue = Null # representation of no value, explicitly assigned","title":"Data Types"},{"location":"dev/Languages/javascript/#arrays","text":"","title":"Arrays"},{"location":"dev/Languages/javascript/#declaration-and-initialization","text":"let arr = [1, 2, 3];","title":"Declaration and Initialization"},{"location":"dev/Languages/javascript/#common-methods","text":"arr.push(4); // [1, 2, 3, 4] arr.pop(); // [1, 2, 3] arr.shift(); // [2, 3] arr.unshift(1); // [1, 2, 3] arr.indexOf(2); // 1 arr.includes(3); // true","title":"Common Methods"},{"location":"dev/Languages/javascript/#iteration","text":"arr.forEach((item) => { console.log(item); }); let newArr = arr.map((item) => item * 2);","title":"Iteration"},{"location":"dev/Languages/javascript/#objects","text":"","title":"Objects"},{"location":"dev/Languages/javascript/#declaration-and-initialization_1","text":"let obj = { key1: \"value1\", key2: 2, key3: function() { return \"value3\"; } };","title":"Declaration and Initialization"},{"location":"dev/Languages/javascript/#accessing-properties","text":"console.log(obj.key1); // \"value1\" console.log(obj[\"key2\"]); // 2","title":"Accessing Properties"},{"location":"dev/Languages/javascript/#addingmodifying-properties","text":"obj.key4 = \"value4\"; obj[\"key5\"] = 5;","title":"Adding/Modifying Properties"},{"location":"dev/Languages/javascript/#deleting-properties","text":"delete obj.key1;","title":"Deleting Properties"},{"location":"dev/Languages/javascript/#conditional-statements","text":"if (condition) { // code block } else if (anotherCondition) { // code block } else { // code block }","title":"Conditional Statements"},{"location":"dev/Languages/javascript/#error-handling","text":"try { // code that may throw an error } catch (error) { console.error(error.message); } finally { // code to be executed regardless of error }","title":"Error Handling"},{"location":"dev/Languages/javascript/#switch-statement","text":"switch (expression) { case x: // code block break; case y: // code block break; default: // code block }","title":"Switch Statement"},{"location":"dev/Languages/javascript/#loops","text":"","title":"Loops"},{"location":"dev/Languages/javascript/#for","text":"for (let i = 0; i < 5; i++) { console.log(i); }","title":"For"},{"location":"dev/Languages/javascript/#while","text":"let i = 0; while (i < 5) { console.log(i); i++; }","title":"While"},{"location":"dev/Languages/javascript/#do-while","text":"let i = 0; do { console.log(i); i++; } while (i < 5);","title":"Do-While"},{"location":"dev/Languages/javascript/#functions","text":"# Function Declaration function myFunction(a, b) { return a + b; } # Function Expression const myFunction = function(a, b) { return a + b; }; # Arrow Function const myFunction = (a, b) => a + b;","title":"Functions"},{"location":"dev/Languages/javascript/#asyncawait","text":"async function fetchData() { try { let response = await fetch('https://api.example.com/data'); let data = await response.json(); console.log(data); } catch (error) { console.error('Error:', error); } }","title":"Async/Await"},{"location":"dev/Languages/javascript/#promises","text":"let promise = new Promise((resolve, reject) => { let success = true; if (success) { resolve(\"Success!\"); } else { reject(\"Error!\"); } }); promise.then((message) => { console.log(message); }).catch((error) => { console.log(error); });","title":"Promises"},{"location":"dev/Languages/javascript/#modules","text":"","title":"Modules"},{"location":"dev/Languages/javascript/#importing","text":"import { myVariable, myFunction } from './myModule.js'; import myDefaultFunction from './myModule.js';","title":"Importing"},{"location":"dev/Languages/javascript/#exporting","text":"export const myVariable = 10; export function myFunction() { // function code } export default function() { // default function code }","title":"Exporting"},{"location":"dev/Languages/powershell/","text":"PowerShell Simple but fairly comprehensive cheatsheet of main powershell features and syntax. Comments # Single line comment # This is a comment <# Multi-line comment This is another comment #> Variables # Scalar Variables $number = 10 $bool = $true $string = \"Hello, PowerShell\" # Arrays $array = @(1, 2, 3, 4, 5) #Hash Table $hashTable = @{ \"Key1\" = \"Value1\"; \"Key2\" = \"Value2\" } # Type and casting [int]$intVariable = 10 [string]$stringVariable = \"Explicit Type\" # Scopes $Global:var = \"Global Variable\" # Accessible from anywhere in the script or session $Local:var = \"Local Variable\" # Accessible only within the current function or script $Script:var = \"Script Variable\" # Accessible throughout the script $Private:var = \"Private Variable\" # Accessible only within the current script or function, not in child scopes Conditional Statements # If-else statement if ($variable -eq \"Hello\") { Write-Output \"Greeting\" } elseif ($variable -eq \"Goodbye\") { Write-Output \"Farewell\" } else { Write-Output \"Unknown\" } # Switch statement switch ($variable) { \"Hello\" { Write-Output \"Greeting\" } \"Goodbye\" { Write-Output \"Farewell\" } default { Write-Output \"Unknown\" } } Loops # For loop for ($i = 0; $i -lt 10; $i++) { Write-Output $i } # While loop $i = 0 while ($i -lt 10) { Write-Output $i $i++ } # Do-While loop $i = 0 do { Write-Output $i $i++ } while ($i -lt 10) # ForEach loop $array = @(1, 2, 3, 4, 5) foreach ($item in $array) { Write-Output $item } Functions # Defines a function that returns a greeting message. function Get-Greeting { param ($name = \"World\") return \"Hello, $name!\" } # Calls the Get-Greeting function with the parameter \"Ale\". Get-Greeting -name \"Ale\" Error Handling # Try-Catch block try { $result = 1 / 0 } catch { Write-Output \"An error occurred: $_\" } Modules # Imports the module named ModuleName. Import-Module -Name ModuleName # Lists all available modules. Get-Module -ListAvailable # Removes the module named ModuleName. Remove-Module -Name ModuleName Pipelines # Pass output from one cmdlet to another Get-Process | Where-Object { $_.CPU -gt 100 } | Sort-Object -Property CPU -Descending Cmdlets \"command-lets,\" are specialized commands in the PowerShell environment that perform a single function. The basic syntax of a cmdlet is: <Verb-Noun> [-Parameter <Value>] [<CommonParameters>] Verb-Noun: Cmdlets use a standardized naming convention of Verb-Noun to describe their action. The verb specifies the action (like Get, Set, New, Remove), and the noun specifies the object (like Process, Service, Item, User). Parameters: Cmdlets can have parameters that modify their behavior. These parameters are specified after the cmdlet name. CommonParameters: These are parameters available to all cmdlets, like -Verbose, -Debug, -ErrorAction, -ErrorVariable, etc.","title":"PowerShell"},{"location":"dev/Languages/powershell/#powershell","text":"Simple but fairly comprehensive cheatsheet of main powershell features and syntax.","title":"PowerShell"},{"location":"dev/Languages/powershell/#comments","text":"# Single line comment # This is a comment <# Multi-line comment This is another comment #>","title":"Comments"},{"location":"dev/Languages/powershell/#variables","text":"# Scalar Variables $number = 10 $bool = $true $string = \"Hello, PowerShell\" # Arrays $array = @(1, 2, 3, 4, 5) #Hash Table $hashTable = @{ \"Key1\" = \"Value1\"; \"Key2\" = \"Value2\" } # Type and casting [int]$intVariable = 10 [string]$stringVariable = \"Explicit Type\" # Scopes $Global:var = \"Global Variable\" # Accessible from anywhere in the script or session $Local:var = \"Local Variable\" # Accessible only within the current function or script $Script:var = \"Script Variable\" # Accessible throughout the script $Private:var = \"Private Variable\" # Accessible only within the current script or function, not in child scopes","title":"Variables"},{"location":"dev/Languages/powershell/#conditional-statements","text":"# If-else statement if ($variable -eq \"Hello\") { Write-Output \"Greeting\" } elseif ($variable -eq \"Goodbye\") { Write-Output \"Farewell\" } else { Write-Output \"Unknown\" } # Switch statement switch ($variable) { \"Hello\" { Write-Output \"Greeting\" } \"Goodbye\" { Write-Output \"Farewell\" } default { Write-Output \"Unknown\" } }","title":"Conditional Statements"},{"location":"dev/Languages/powershell/#loops","text":"# For loop for ($i = 0; $i -lt 10; $i++) { Write-Output $i } # While loop $i = 0 while ($i -lt 10) { Write-Output $i $i++ } # Do-While loop $i = 0 do { Write-Output $i $i++ } while ($i -lt 10) # ForEach loop $array = @(1, 2, 3, 4, 5) foreach ($item in $array) { Write-Output $item }","title":"Loops"},{"location":"dev/Languages/powershell/#functions","text":"# Defines a function that returns a greeting message. function Get-Greeting { param ($name = \"World\") return \"Hello, $name!\" } # Calls the Get-Greeting function with the parameter \"Ale\". Get-Greeting -name \"Ale\"","title":"Functions"},{"location":"dev/Languages/powershell/#error-handling","text":"# Try-Catch block try { $result = 1 / 0 } catch { Write-Output \"An error occurred: $_\" }","title":"Error Handling"},{"location":"dev/Languages/powershell/#modules","text":"# Imports the module named ModuleName. Import-Module -Name ModuleName # Lists all available modules. Get-Module -ListAvailable # Removes the module named ModuleName. Remove-Module -Name ModuleName","title":"Modules"},{"location":"dev/Languages/powershell/#pipelines","text":"# Pass output from one cmdlet to another Get-Process | Where-Object { $_.CPU -gt 100 } | Sort-Object -Property CPU -Descending","title":"Pipelines"},{"location":"dev/Languages/powershell/#cmdlets","text":"\"command-lets,\" are specialized commands in the PowerShell environment that perform a single function. The basic syntax of a cmdlet is: <Verb-Noun> [-Parameter <Value>] [<CommonParameters>] Verb-Noun: Cmdlets use a standardized naming convention of Verb-Noun to describe their action. The verb specifies the action (like Get, Set, New, Remove), and the noun specifies the object (like Process, Service, Item, User). Parameters: Cmdlets can have parameters that modify their behavior. These parameters are specified after the cmdlet name. CommonParameters: These are parameters available to all cmdlets, like -Verbose, -Debug, -ErrorAction, -ErrorVariable, etc.","title":"Cmdlets"},{"location":"dev/Languages/python/","text":"Python Programming Language Simple but fairly comprehensive cheatsheet of all main python language features and syntax. Comments # Single line comment \"\"\" Multiline strings, often used as documentation. \"\"\" Variables There are no declarations, only assignments. var = 5 var # => 5 Datatypes Numbers 3 3.23 52.3E-4 Boolean True False Strings (immutable) \"This is a string.\" 'This is also a string.' r\"Newlines are indicated by \\n\" (raw string, no special processing ) f\"She said her name is {name}.\" (formatted string, name is a variable) None (is an object) None Data Structures Lists - Hold an ordered and changeable collection of items. Lists allow duplicate values. list = [] list = [\"A\", 5, 6, True] Get length. len(list) Check for existence. 1 in list # => True Access a list like any array. list[0] list[-1] (last element) Get index of first matching item. list.index(value) Insert, append and pop. list.insert(index, value) list.append(3) # list is now [1, 2, 4, 3] list.pop() # => 3 list is now [1, 2, 4] Slice syntax. list[start:end:step] list[2:] list[:3] list[1:3] list[::2] Add lists. list + other_list Remove element. del list[index] Remove first occurrence of a value. list.remove(value) Tuples - Hold an ordered and immutable collection of items. tuple = (1, 2, 3) tup[0] # => 1 tup[0] = 3 # Raises a TypeError Most of the list operations are valid for tuples too Dictionaries - Store keys to values mappings. Dictionary items are ordered, changeable and does not allow duplicates. dictionary = {} dictionary = {\"one\": 1, \"two\": 2, \"three\": 3} Keys for dictionaries have to be immutable types. Immutable types include ints, floats, strings, tuples. Look up values using corresponding key. dictionary[\"one\"] # => 1 dictionary.get(\"one\") # => 1 Get all keys / values. list(dictionary.keys()) # => [\"one\", \"two\", \"three\"] list(dictionary.values()) # => [1, 2, 3] Check for existence of keys. \"one\" in dictionary # => True 1 in dictionary # => False Adding an element. dictionary[\"four\"] = 4 dictionary.update({\"four\":4}) Remove keys. del dictionary[\"one\"] Sets - Hold an unordered, unchangeable collection of items. Sets do not allow duplicate values. set = set() set = {1, 2, 2, 3, 3, 4} # some_set is now {1, 2, 3, 4} Elements of a set have to be immutable. Add items. set.add(5) # set is now {1, 2, 3, 4, 5} set.add(5) # remains as before {1, 2, 3, 4, 5} Intersection ( & ), union ( | ), difference ( - ), symmetric difference ( ^ ), superset. other_set = {3, 4, 5, 6} set & other_set # => {3, 4, 5} filled_set | other_set # => {1, 2, 3, 4, 5, 6} {1, 2, 3, 4} - {2, 3, 5} # => {1, 4} {1, 2, 3, 4} ^ {2, 3, 5} # => {1, 4, 5} {1, 2} >= {1, 2, 3} # => False {1, 2} <= {1, 2, 3} # => True Check for existence. 2 in set # => True 10 in set # => False Operators Mathematical operators are straightforward. 1 + 1 # => 2 8 - 1 # => 7 10 * 2 # => 20 35 / 5 # => 7.0 Integer division rounds down both positive and negative numbers. 5 // 3 # => 1 -5 // 3 # => -2 5.0 // 3.0 # => 1.0 -5.0 // 3.0 # => -2.0 The result of division is always a float. 10.0 / 3 # => 3.3333333333333335 Modulo operator. 7 % 3 # => 1 Exponentiation operator. 2**3 # => 8 Boolean operators. not False # => True not True # => False False or True # => True True and False # => False Comparison operators look at the numerical value of booleans (True and False are actually 1 and 0). 0 == False # => True 2 > True # => True None, 0, and empty strings/lists/dicts/tuples/sets all evaluate to False, all other values are True. bool(0) # => False bool(\"\") # => False bool([]) # => False bool(None) # => False Equality , inequality and comparisons operators. 1 == 1 # => True 2 == 1 # => False 1 != 1 # => False 2 != 1 # => True 1 < 10 # => True 1 > 10 # => False 2 <= 2 # => True 2 >= 2 # => True \" is \" checks if two variables refer to the same object, but \" == \" checks if the objects have the same values. a = [1, 2, 3, 4] b = a b is a # => True b == a # => True b = [1, 2, 3, 4] b is a # => False b == a # => True Control Flow if statement. if var > 10: # do something elif var < 10: # do something else: # do something For loops. # range(lower, upper, step), where upper bound is excluded for i in range(4): print(i) for i in range(4, 8): # print(i) for i in range(4, 8, 2): print(i) # iterate over an iterable object (an iterable is an object that can be treated as a sequence). for animal in [\"dog\", \"cat\", \"mouse\"]: print(f\"{animal} is a mammal\") animals = [\"dog\", \"cat\", \"mouse\"] for i, value in enumerate(animals): print(i, value) While loops. x = 0 while x < 4: print(x) x += 1 try/except blocks. try: # try something raise IndexError(\"This is an index error\") except IndexError as error: # handle one or more exceptions print(f\"Oh no: {error}\") except (TypeError, NameError): pass else: # run when no exceptions is raised in try print(\"All good!\") finally: # always execute anyway print(\"...anyway!\") with statement. with open(\"file.txt\") as file: for line in file: print(line) Functions Create a new function . def add(x, y): return x + y Calling functions with parameters or keyword arguments . add(5, 7) # => 12 add(y=7, x=5) # => 12 Define a function that take a variable number of positional arguments (stored in a tuple). def func(*args): return args func(1, 2, 3) # => (1, 2, 3) You can define functions that take a variable number of keyword arguments (stored in a dictionary). def func(**kwargs): return kwargs func(english=\"eng\", italian=\"ita\") # => {\"english\": \"eng\", \"italian\": \"ita\"} Both can be used at once. def func(*args, **kwargs): print(args) print(kwargs) func(1, 2, a=3, b=4) # => (1, 2) {\"a\": 3, \"b\": 4} It's possible to return multiple values (returned values are stored in a tuple). def func(x, y): return y, x func(\"a\", \"b\") # => ('b', 'a') Global and local scope . x = 5 def set_local(num): # local scope x = num print(x) def set_global(num): # global refers to global variable global x print(x) x = num print(x) set_local(10) # => 10 set_global(20) # => 5 20 Lambdas (anonymous functions). func = lambda a : a + 10 func(5) # => 15 Return functions. def parent_func(x): def child_func(y): return x + y return child_func func = parent_func(10) func(3) # => 13 Classes Define a class . class Person: # class variables shared by all instances species = \"H. sapiens\" # initializer method (when a class defines an __init__() method, class instantiation automatically invokes __init__() for the newly created class instance) def __init__(self, name, surname, age): # instance variables unique to each instance self.age = age self.name = name self.surname = surname # an instance method (all methods take \"self\" as the first argument) def greet(self): print(f\"Hello, I am {self.name} {self.surname}.\") Define inheritance . class Engineer(Person): # child's __init__() function overrides the inheritance of the parent's __init__() function so it's necessary to add a call to the parent's __init__(). def __init__(self, name, surname, age, job, pay): # call to parent initializer Person.__init__(self, name, surname, age) # or super().__init__(name, surname, age) self.job = job self.pay = pay def brag_about_job(self): print(f\"Currently working as a {self.job}\") def brag_about_pay(self): print(f\"I'm being paied around {self.pay} a year\") Modules __name__ checks makes sure the code is only executed when the module is the main program. if __name__ == '__main__': # execution Import modules. import math math.pow(2, 3) # => 8.0 Import specific functions from a module. from math import pow pow(2, 3) # => 8.0 Import all functions from a module (not recommended). from math import * pow(2, 3) # => 8.0 Customize module names. import math as m m.pow(2, 3) # => 8.0 Find which functions and attributes are defined in a module. import math dir(math)","title":"Python"},{"location":"dev/Languages/python/#python-programming-language","text":"Simple but fairly comprehensive cheatsheet of all main python language features and syntax.","title":"Python Programming Language"},{"location":"dev/Languages/python/#comments","text":"# Single line comment \"\"\" Multiline strings, often used as documentation. \"\"\"","title":"Comments"},{"location":"dev/Languages/python/#variables","text":"There are no declarations, only assignments. var = 5 var # => 5","title":"Variables"},{"location":"dev/Languages/python/#datatypes","text":"Numbers 3 3.23 52.3E-4 Boolean True False Strings (immutable) \"This is a string.\" 'This is also a string.' r\"Newlines are indicated by \\n\" (raw string, no special processing ) f\"She said her name is {name}.\" (formatted string, name is a variable) None (is an object) None","title":"Datatypes"},{"location":"dev/Languages/python/#data-structures","text":"Lists - Hold an ordered and changeable collection of items. Lists allow duplicate values. list = [] list = [\"A\", 5, 6, True] Get length. len(list) Check for existence. 1 in list # => True Access a list like any array. list[0] list[-1] (last element) Get index of first matching item. list.index(value) Insert, append and pop. list.insert(index, value) list.append(3) # list is now [1, 2, 4, 3] list.pop() # => 3 list is now [1, 2, 4] Slice syntax. list[start:end:step] list[2:] list[:3] list[1:3] list[::2] Add lists. list + other_list Remove element. del list[index] Remove first occurrence of a value. list.remove(value) Tuples - Hold an ordered and immutable collection of items. tuple = (1, 2, 3) tup[0] # => 1 tup[0] = 3 # Raises a TypeError Most of the list operations are valid for tuples too Dictionaries - Store keys to values mappings. Dictionary items are ordered, changeable and does not allow duplicates. dictionary = {} dictionary = {\"one\": 1, \"two\": 2, \"three\": 3} Keys for dictionaries have to be immutable types. Immutable types include ints, floats, strings, tuples. Look up values using corresponding key. dictionary[\"one\"] # => 1 dictionary.get(\"one\") # => 1 Get all keys / values. list(dictionary.keys()) # => [\"one\", \"two\", \"three\"] list(dictionary.values()) # => [1, 2, 3] Check for existence of keys. \"one\" in dictionary # => True 1 in dictionary # => False Adding an element. dictionary[\"four\"] = 4 dictionary.update({\"four\":4}) Remove keys. del dictionary[\"one\"] Sets - Hold an unordered, unchangeable collection of items. Sets do not allow duplicate values. set = set() set = {1, 2, 2, 3, 3, 4} # some_set is now {1, 2, 3, 4} Elements of a set have to be immutable. Add items. set.add(5) # set is now {1, 2, 3, 4, 5} set.add(5) # remains as before {1, 2, 3, 4, 5} Intersection ( & ), union ( | ), difference ( - ), symmetric difference ( ^ ), superset. other_set = {3, 4, 5, 6} set & other_set # => {3, 4, 5} filled_set | other_set # => {1, 2, 3, 4, 5, 6} {1, 2, 3, 4} - {2, 3, 5} # => {1, 4} {1, 2, 3, 4} ^ {2, 3, 5} # => {1, 4, 5} {1, 2} >= {1, 2, 3} # => False {1, 2} <= {1, 2, 3} # => True Check for existence. 2 in set # => True 10 in set # => False","title":"Data Structures"},{"location":"dev/Languages/python/#operators","text":"Mathematical operators are straightforward. 1 + 1 # => 2 8 - 1 # => 7 10 * 2 # => 20 35 / 5 # => 7.0 Integer division rounds down both positive and negative numbers. 5 // 3 # => 1 -5 // 3 # => -2 5.0 // 3.0 # => 1.0 -5.0 // 3.0 # => -2.0 The result of division is always a float. 10.0 / 3 # => 3.3333333333333335 Modulo operator. 7 % 3 # => 1 Exponentiation operator. 2**3 # => 8 Boolean operators. not False # => True not True # => False False or True # => True True and False # => False Comparison operators look at the numerical value of booleans (True and False are actually 1 and 0). 0 == False # => True 2 > True # => True None, 0, and empty strings/lists/dicts/tuples/sets all evaluate to False, all other values are True. bool(0) # => False bool(\"\") # => False bool([]) # => False bool(None) # => False Equality , inequality and comparisons operators. 1 == 1 # => True 2 == 1 # => False 1 != 1 # => False 2 != 1 # => True 1 < 10 # => True 1 > 10 # => False 2 <= 2 # => True 2 >= 2 # => True \" is \" checks if two variables refer to the same object, but \" == \" checks if the objects have the same values. a = [1, 2, 3, 4] b = a b is a # => True b == a # => True b = [1, 2, 3, 4] b is a # => False b == a # => True","title":"Operators"},{"location":"dev/Languages/python/#control-flow","text":"if statement. if var > 10: # do something elif var < 10: # do something else: # do something For loops. # range(lower, upper, step), where upper bound is excluded for i in range(4): print(i) for i in range(4, 8): # print(i) for i in range(4, 8, 2): print(i) # iterate over an iterable object (an iterable is an object that can be treated as a sequence). for animal in [\"dog\", \"cat\", \"mouse\"]: print(f\"{animal} is a mammal\") animals = [\"dog\", \"cat\", \"mouse\"] for i, value in enumerate(animals): print(i, value) While loops. x = 0 while x < 4: print(x) x += 1 try/except blocks. try: # try something raise IndexError(\"This is an index error\") except IndexError as error: # handle one or more exceptions print(f\"Oh no: {error}\") except (TypeError, NameError): pass else: # run when no exceptions is raised in try print(\"All good!\") finally: # always execute anyway print(\"...anyway!\") with statement. with open(\"file.txt\") as file: for line in file: print(line)","title":"Control Flow"},{"location":"dev/Languages/python/#functions","text":"Create a new function . def add(x, y): return x + y Calling functions with parameters or keyword arguments . add(5, 7) # => 12 add(y=7, x=5) # => 12 Define a function that take a variable number of positional arguments (stored in a tuple). def func(*args): return args func(1, 2, 3) # => (1, 2, 3) You can define functions that take a variable number of keyword arguments (stored in a dictionary). def func(**kwargs): return kwargs func(english=\"eng\", italian=\"ita\") # => {\"english\": \"eng\", \"italian\": \"ita\"} Both can be used at once. def func(*args, **kwargs): print(args) print(kwargs) func(1, 2, a=3, b=4) # => (1, 2) {\"a\": 3, \"b\": 4} It's possible to return multiple values (returned values are stored in a tuple). def func(x, y): return y, x func(\"a\", \"b\") # => ('b', 'a') Global and local scope . x = 5 def set_local(num): # local scope x = num print(x) def set_global(num): # global refers to global variable global x print(x) x = num print(x) set_local(10) # => 10 set_global(20) # => 5 20 Lambdas (anonymous functions). func = lambda a : a + 10 func(5) # => 15 Return functions. def parent_func(x): def child_func(y): return x + y return child_func func = parent_func(10) func(3) # => 13","title":"Functions"},{"location":"dev/Languages/python/#classes","text":"Define a class . class Person: # class variables shared by all instances species = \"H. sapiens\" # initializer method (when a class defines an __init__() method, class instantiation automatically invokes __init__() for the newly created class instance) def __init__(self, name, surname, age): # instance variables unique to each instance self.age = age self.name = name self.surname = surname # an instance method (all methods take \"self\" as the first argument) def greet(self): print(f\"Hello, I am {self.name} {self.surname}.\") Define inheritance . class Engineer(Person): # child's __init__() function overrides the inheritance of the parent's __init__() function so it's necessary to add a call to the parent's __init__(). def __init__(self, name, surname, age, job, pay): # call to parent initializer Person.__init__(self, name, surname, age) # or super().__init__(name, surname, age) self.job = job self.pay = pay def brag_about_job(self): print(f\"Currently working as a {self.job}\") def brag_about_pay(self): print(f\"I'm being paied around {self.pay} a year\")","title":"Classes"},{"location":"dev/Languages/python/#modules","text":"__name__ checks makes sure the code is only executed when the module is the main program. if __name__ == '__main__': # execution Import modules. import math math.pow(2, 3) # => 8.0 Import specific functions from a module. from math import pow pow(2, 3) # => 8.0 Import all functions from a module (not recommended). from math import * pow(2, 3) # => 8.0 Customize module names. import math as m m.pow(2, 3) # => 8.0 Find which functions and attributes are defined in a module. import math dir(math)","title":"Modules"},{"location":"dev/Platforms/linux/package%20managers/apt/","text":"APT Advanced package tool, or APT, is a user interface that works with core libraries to handle the installation and removal of software on Debian, and Debian-based linux distributions Install a package apt install PACKAGE Uninstall a package apt remove PACKAGE Uninstall a package and delete configuration files apt purge PACKAGE List available packages apt list [--installed | --upgradeable] Search for a package apt search PACKAGE Provide information about a package apt show PACKAGE Remove installed dependencies that are no longer required apt autoremove Check for updates information from all configured sources apt update Install available upgrades apt upgrade Install available upgrades and remove obsolete packages apt full-upgrade Edit your sources.list file apt edit-sources Configuration file The source list /etc/apt/sources.list and the files contained in /etc/apt/sources.list.d/ are designed to support any number of active sources and a variety of source media. The files list one source per line (one-line style) or contain multiline stanzas defining one or more sources per stanza (deb822 style), with the most preferred source listed first (in case a single version is available from more than one source). Files in this format have the extension .list. Each line specifying a source starts with a type (e.g. deb-src) followed by options and arguments for this type. Individual entries cannot be continued onto a following line. Empty lines are ignored , and a # character anywhere on a line marks the remainder of that line as a comment . Consequently an entry can be disabled by commenting out the entire line.","title":"APT"},{"location":"dev/Platforms/linux/package%20managers/apt/#apt","text":"Advanced package tool, or APT, is a user interface that works with core libraries to handle the installation and removal of software on Debian, and Debian-based linux distributions Install a package apt install PACKAGE Uninstall a package apt remove PACKAGE Uninstall a package and delete configuration files apt purge PACKAGE List available packages apt list [--installed | --upgradeable] Search for a package apt search PACKAGE Provide information about a package apt show PACKAGE Remove installed dependencies that are no longer required apt autoremove Check for updates information from all configured sources apt update Install available upgrades apt upgrade Install available upgrades and remove obsolete packages apt full-upgrade Edit your sources.list file apt edit-sources","title":"APT"},{"location":"dev/Platforms/linux/package%20managers/apt/#configuration-file","text":"The source list /etc/apt/sources.list and the files contained in /etc/apt/sources.list.d/ are designed to support any number of active sources and a variety of source media. The files list one source per line (one-line style) or contain multiline stanzas defining one or more sources per stanza (deb822 style), with the most preferred source listed first (in case a single version is available from more than one source). Files in this format have the extension .list. Each line specifying a source starts with a type (e.g. deb-src) followed by options and arguments for this type. Individual entries cannot be continued onto a following line. Empty lines are ignored , and a # character anywhere on a line marks the remainder of that line as a comment . Consequently an entry can be disabled by commenting out the entire line.","title":"Configuration file"},{"location":"dev/Platforms/linux/package%20managers/brew/","text":"BREW Homebrew is a free and open-source software package management system for macOS Install a formula brew install FORMULA Reinstall a formula or cask brew reinstall FORMULA Uninstall a formula brew uninstall FORMULA List installed formulae and casks brew list List explicitly installed formulae (not dependencies) brew leaves Display brief statistics of Homebrew installation or, if a formula or cask is provided, show a summary brew info [FORMULA] Search for a formula (with a name or a /regex/) brew search FORMULA | /FORMULA/ Uninstall no longer needed dependencies brew autoremove Remove outdated downloads and versions for all formulae and casks brew cleanup Check system for potential problems brew doctor Print export statements . When run in a shell, add installation of Homebrew to your PATH, MANPATH, and INFOPATH. The variables HOMEBREW_PREFIX, HOMEBREW_CELLAR and HOMEBREW_REPOSITORY are also exported to avoid querying them multiple times brew shellenv Pin the specified formula, preventing it from being upgraded brew pin FORMULA Unpin formula, allowing it to be upgraded brew unpin FORMULA Fetch the newest version of Homebrew and all formulae from GitHub brew update Upgrade outdated casks and outdated, unpinned formulae brew upgrade","title":"Brew"},{"location":"dev/Platforms/linux/package%20managers/brew/#brew","text":"Homebrew is a free and open-source software package management system for macOS Install a formula brew install FORMULA Reinstall a formula or cask brew reinstall FORMULA Uninstall a formula brew uninstall FORMULA List installed formulae and casks brew list List explicitly installed formulae (not dependencies) brew leaves Display brief statistics of Homebrew installation or, if a formula or cask is provided, show a summary brew info [FORMULA] Search for a formula (with a name or a /regex/) brew search FORMULA | /FORMULA/ Uninstall no longer needed dependencies brew autoremove Remove outdated downloads and versions for all formulae and casks brew cleanup Check system for potential problems brew doctor Print export statements . When run in a shell, add installation of Homebrew to your PATH, MANPATH, and INFOPATH. The variables HOMEBREW_PREFIX, HOMEBREW_CELLAR and HOMEBREW_REPOSITORY are also exported to avoid querying them multiple times brew shellenv Pin the specified formula, preventing it from being upgraded brew pin FORMULA Unpin formula, allowing it to be upgraded brew unpin FORMULA Fetch the newest version of Homebrew and all formulae from GitHub brew update Upgrade outdated casks and outdated, unpinned formulae brew upgrade","title":"BREW"},{"location":"dev/Platforms/linux/package%20managers/dnf/","text":"DNF DNF or Dandified YUM is the next-generation version of the Yellowdog Updater, Modified (yum), a package manager for .rpm-based linux distributions Install a package dnf install PACKAGE Reinstall a package dnf reinstall PACKAGE Revert a package to the previous version dnf downgrade PACKAGE Uninstall a package dnf remove PACKAGE Remove installed dependencies that are no longer required dnf autoremove Search for a package dnf search PACKAGE Provide information about a package dnf info PACKAGE Check for updates without installing the packages dnf check-update Check and perform updates dnf upgrade Group command List available groups dnf group list Install a group dnf group install \"GROUP_NAME\" Remove a group dnf group remove \"GROUP_NAME\" Configuration file DNF by default uses the global configuration file at /etc/dnf/dnf.conf and all *.repo files found under /etc/yum.repos.d . The latter is typically used for repository configuration and takes precedence over global configuration. The configuration file has INI format consisting of section declaration and name=value options below each on separate line. There are two types of sections in the configuration files: main and repository . Main section defines all global configuration options. The repository sections define the configuration for each (remote or local) repository. The section name of the repository in brackets serve as repo ID reference and should be unique across configuration files. The minimal repository configuration file should aside from repo ID consists of baseurl, metalink or mirrorlist option definition.","title":"DNF"},{"location":"dev/Platforms/linux/package%20managers/dnf/#dnf","text":"DNF or Dandified YUM is the next-generation version of the Yellowdog Updater, Modified (yum), a package manager for .rpm-based linux distributions Install a package dnf install PACKAGE Reinstall a package dnf reinstall PACKAGE Revert a package to the previous version dnf downgrade PACKAGE Uninstall a package dnf remove PACKAGE Remove installed dependencies that are no longer required dnf autoremove Search for a package dnf search PACKAGE Provide information about a package dnf info PACKAGE Check for updates without installing the packages dnf check-update Check and perform updates dnf upgrade","title":"DNF"},{"location":"dev/Platforms/linux/package%20managers/dnf/#group-command","text":"List available groups dnf group list Install a group dnf group install \"GROUP_NAME\" Remove a group dnf group remove \"GROUP_NAME\"","title":"Group command"},{"location":"dev/Platforms/linux/package%20managers/dnf/#configuration-file","text":"DNF by default uses the global configuration file at /etc/dnf/dnf.conf and all *.repo files found under /etc/yum.repos.d . The latter is typically used for repository configuration and takes precedence over global configuration. The configuration file has INI format consisting of section declaration and name=value options below each on separate line. There are two types of sections in the configuration files: main and repository . Main section defines all global configuration options. The repository sections define the configuration for each (remote or local) repository. The section name of the repository in brackets serve as repo ID reference and should be unique across configuration files. The minimal repository configuration file should aside from repo ID consists of baseurl, metalink or mirrorlist option definition.","title":"Configuration file"},{"location":"dev/Platforms/linux/package%20managers/pacman/","text":"PACMAN Pacman is a simple library-based package manager which manages software packages on Arch-based linux distributions Install a package or group pacman -S PACKAGE | PACKAGE_GROUP Install a local package pacman -U PACKAGE Uninstall a package pacman -R PACKAGE Uninstall a package and its dependencies pacman -Rs PACKAGE Pacman queries the local package database with the -Q flag, the sync database with the -S flag and the files database with the -F flag. -s is the builtin ERE flag. List installed packages pacman -Q Search for a package pacman -Ss PACKAGE Search for already installed packages pacman -Qs PACKAGE Provide information about a package pacman -Si PACKAGE Remove all files from cache pacman -Scc Synchronize the repository databases and update the system's packages (excluding local packages) pacman -Syu Configuration file Pacman's settings are located in /etc/pacman.conf : this is the place where the user configures the program to work in the desired manner. Pacman will attempt to read pacman.conf each time it is invoked. This configuration file is divided into sections or repositories . Each section defines a package repository that pacman can use when searching for packages in --sync mode. The exception to this is the [options] section, which defines global options. Comments are only supported by beginning a line with the hash ( # ) symbol. Comments cannot begin in the middle of a line.","title":"Pacman"},{"location":"dev/Platforms/linux/package%20managers/pacman/#pacman","text":"Pacman is a simple library-based package manager which manages software packages on Arch-based linux distributions Install a package or group pacman -S PACKAGE | PACKAGE_GROUP Install a local package pacman -U PACKAGE Uninstall a package pacman -R PACKAGE Uninstall a package and its dependencies pacman -Rs PACKAGE Pacman queries the local package database with the -Q flag, the sync database with the -S flag and the files database with the -F flag. -s is the builtin ERE flag. List installed packages pacman -Q Search for a package pacman -Ss PACKAGE Search for already installed packages pacman -Qs PACKAGE Provide information about a package pacman -Si PACKAGE Remove all files from cache pacman -Scc Synchronize the repository databases and update the system's packages (excluding local packages) pacman -Syu","title":"PACMAN"},{"location":"dev/Platforms/linux/package%20managers/pacman/#configuration-file","text":"Pacman's settings are located in /etc/pacman.conf : this is the place where the user configures the program to work in the desired manner. Pacman will attempt to read pacman.conf each time it is invoked. This configuration file is divided into sections or repositories . Each section defines a package repository that pacman can use when searching for packages in --sync mode. The exception to this is the [options] section, which defines global options. Comments are only supported by beginning a line with the hash ( # ) symbol. Comments cannot begin in the middle of a line.","title":"Configuration file"},{"location":"dev/Platforms/linux/utilities/cat/","text":"CAT The cat utility reads files sequentially, writing them to the standard output. Write file to standard output cat FILE Concatenate files cat FILE1 FILE2 > FILE3 Number the output lines cat -n FILE Display non-printing characters and EOF cat -e FILE","title":"cat"},{"location":"dev/Platforms/linux/utilities/cat/#cat","text":"The cat utility reads files sequentially, writing them to the standard output. Write file to standard output cat FILE Concatenate files cat FILE1 FILE2 > FILE3 Number the output lines cat -n FILE Display non-printing characters and EOF cat -e FILE","title":"CAT"},{"location":"dev/Platforms/linux/utilities/exa/","text":"EXA exa is an improved file lister with more features and better defaults than the standard ls command. Usage : exa [OPTIONS] [FILES] || [DIRECTORIES] DISPLAY OPTIONS -R, --recurse recurse into directories -1, --oneline display one entry per line -T, --tree recurse into directories as a tree -F, --classify display type indicator by file names -l, --long display extended file metadata as a table FILTERING AND SORTING OPTIONS -r, --reverse reverse the sort order -a, --all show hidden and 'dot' files -D, --only-dirs list only directories -s, --sort SORT_FIELD which field to sort by -L, --level DEPTH limit the depth of recursion --group-directories-first list directories before other files LONG VIEW OPTIONS -i, --inode list each file's inode number -n, --numeric list numeric user and group IDs -h, --header add a header row to each column -S, --blocks show number of file system blocks -H, --links list each file's number of hard links -b, --binary list file sizes with binary prefixes --git list each file's Git status, if tracked or ignored -B, --bytes list file sizes in bytes, without any prefixes -@, --extended list each file's extended attributes and sizes --octal-permissions list each file's permission in octal format","title":"exa"},{"location":"dev/Platforms/linux/utilities/exa/#exa","text":"exa is an improved file lister with more features and better defaults than the standard ls command. Usage : exa [OPTIONS] [FILES] || [DIRECTORIES]","title":"EXA"},{"location":"dev/Platforms/linux/utilities/exa/#display-options","text":"-R, --recurse recurse into directories -1, --oneline display one entry per line -T, --tree recurse into directories as a tree -F, --classify display type indicator by file names -l, --long display extended file metadata as a table","title":"DISPLAY OPTIONS"},{"location":"dev/Platforms/linux/utilities/exa/#filtering-and-sorting-options","text":"-r, --reverse reverse the sort order -a, --all show hidden and 'dot' files -D, --only-dirs list only directories -s, --sort SORT_FIELD which field to sort by -L, --level DEPTH limit the depth of recursion --group-directories-first list directories before other files","title":"FILTERING AND SORTING OPTIONS"},{"location":"dev/Platforms/linux/utilities/exa/#long-view-options","text":"-i, --inode list each file's inode number -n, --numeric list numeric user and group IDs -h, --header add a header row to each column -S, --blocks show number of file system blocks -H, --links list each file's number of hard links -b, --binary list file sizes with binary prefixes --git list each file's Git status, if tracked or ignored -B, --bytes list file sizes in bytes, without any prefixes -@, --extended list each file's extended attributes and sizes --octal-permissions list each file's permission in octal format","title":"LONG VIEW OPTIONS"},{"location":"dev/Platforms/linux/utilities/find/","text":"FIND Search for files in a directory hierarchy. find PATH [OPTIONS] COMMANDS -L - Follow symbolic links -P - Never follow symbolic links -H - Do not follow symbolic links, except while processing command line arguments -name - Find files by name -delete - Delete matched files -iname - Find files by name (case insensitive) -maxdepth - Descend at most x directory levels -regex - Matches pattern using regular expression (BRE) -size - Find by size k - kilobytes M - megabytes G - gigabytes T - terabytes P - petabytes -type - Filter files for type b - Block special c - Character special d - Directory f - Regular file l - Symbolic link p - FIFO s - Socket -mtime x[smhdw] - Find by modified time s - second m - minute (60 seconds) h - hour (60 minutes) d - day (24 hours) w - week (7 days)","title":"find"},{"location":"dev/Platforms/linux/utilities/find/#find","text":"Search for files in a directory hierarchy. find PATH [OPTIONS] COMMANDS -L - Follow symbolic links -P - Never follow symbolic links -H - Do not follow symbolic links, except while processing command line arguments -name - Find files by name -delete - Delete matched files -iname - Find files by name (case insensitive) -maxdepth - Descend at most x directory levels -regex - Matches pattern using regular expression (BRE) -size - Find by size k - kilobytes M - megabytes G - gigabytes T - terabytes P - petabytes -type - Filter files for type b - Block special c - Character special d - Directory f - Regular file l - Symbolic link p - FIFO s - Socket -mtime x[smhdw] - Find by modified time s - second m - minute (60 seconds) h - hour (60 minutes) d - day (24 hours) w - week (7 days)","title":"FIND"},{"location":"dev/Platforms/linux/utilities/less/","text":"LESS Less is a command line utility that displays the contents of a file or a command output, one page at a time (both forward and backward). Open a file less [OPTIONS] FILENAME -E - Exit when EOF -N - Display line numbers -X - Display output without clearing the screen on exit -p - Start at the first occurrence of \"pattern\" in the file Redirect some output to less ps aux | less Keyboard Navigation b - Move up one page spacebar - Move down one page g - Go to first line G - Go to last line Ng - Go to the Nth line n - When searching, go to the next occurrence N - When searching, go to the previous occurrence /search - Search forward from the current position for the \"search\" ?search - Search backward from the current position for the \"search\" q - Quit less","title":"less"},{"location":"dev/Platforms/linux/utilities/less/#less","text":"Less is a command line utility that displays the contents of a file or a command output, one page at a time (both forward and backward). Open a file less [OPTIONS] FILENAME -E - Exit when EOF -N - Display line numbers -X - Display output without clearing the screen on exit -p - Start at the first occurrence of \"pattern\" in the file Redirect some output to less ps aux | less","title":"LESS"},{"location":"dev/Platforms/linux/utilities/less/#keyboard-navigation","text":"b - Move up one page spacebar - Move down one page g - Go to first line G - Go to last line Ng - Go to the Nth line n - When searching, go to the next occurrence N - When searching, go to the previous occurrence /search - Search forward from the current position for the \"search\" ?search - Search backward from the current position for the \"search\" q - Quit less","title":"Keyboard Navigation"},{"location":"dev/Platforms/linux/utilities/ls/","text":"LS The ls command list directory contents. Usage : ls [OPTION] [FILE] DISPLAY OPTIONS -1 list one file per line -C list entries by columns -l use a long listing format -F, --classify append indicator to entries -A, --almost-all do not list implied . and .. -a, --all do not ignore entries starting with . --group-directories-first group directories before files FILTERING AND SORTING OPTIONS -t sort by time, newest first -S sort by file size, largest first -r, --reverse reverse order while sorting -R, --recursive list subdirectories recursively --sort=WORD sort by WORD instead of name: none (-U), size (-S), time (-t), version (-v), extension (-X) LONG VIEW OPTIONS --author print the author of each file -i, --inode list each file's inode number -h, --human-readable print sizes like 1K 234M 2G etc","title":"ls"},{"location":"dev/Platforms/linux/utilities/ls/#ls","text":"The ls command list directory contents. Usage : ls [OPTION] [FILE]","title":"LS"},{"location":"dev/Platforms/linux/utilities/ls/#display-options","text":"-1 list one file per line -C list entries by columns -l use a long listing format -F, --classify append indicator to entries -A, --almost-all do not list implied . and .. -a, --all do not ignore entries starting with . --group-directories-first group directories before files","title":"DISPLAY OPTIONS"},{"location":"dev/Platforms/linux/utilities/ls/#filtering-and-sorting-options","text":"-t sort by time, newest first -S sort by file size, largest first -r, --reverse reverse order while sorting -R, --recursive list subdirectories recursively --sort=WORD sort by WORD instead of name: none (-U), size (-S), time (-t), version (-v), extension (-X)","title":"FILTERING AND SORTING OPTIONS"},{"location":"dev/Platforms/linux/utilities/ls/#long-view-options","text":"--author print the author of each file -i, --inode list each file's inode number -h, --human-readable print sizes like 1K 234M 2G etc","title":"LONG VIEW OPTIONS"},{"location":"dev/Platforms/linux/utilities/most/","text":"MOST Most is a paging program that displays, one windowful at a time, the contents of a file on a terminal. Open a file most [OPTIONS] filename -b - Display file in hexadecimal notation (16 bytes per line) +line - Start up at the specified \"line\" +/string - Start at line containing first occurrence of \"string\" Redirect some output to most ps aux | most Keyboard Navigation u - Move up one page spacebar - Move down one page t - Go to the top of buffer b - Go to the bottom of buffer g - Prompt for a line number to jump to n - When searching, go to the next occurrence /search - Search forward from current position for \"search\" ?search - Search backward from current position for \"search\" e - Edit file q - Quit most","title":"most"},{"location":"dev/Platforms/linux/utilities/most/#most","text":"Most is a paging program that displays, one windowful at a time, the contents of a file on a terminal. Open a file most [OPTIONS] filename -b - Display file in hexadecimal notation (16 bytes per line) +line - Start up at the specified \"line\" +/string - Start at line containing first occurrence of \"string\" Redirect some output to most ps aux | most","title":"MOST"},{"location":"dev/Platforms/linux/utilities/most/#keyboard-navigation","text":"u - Move up one page spacebar - Move down one page t - Go to the top of buffer b - Go to the bottom of buffer g - Prompt for a line number to jump to n - When searching, go to the next occurrence /search - Search forward from current position for \"search\" ?search - Search backward from current position for \"search\" e - Edit file q - Quit most","title":"Keyboard Navigation"},{"location":"dev/Platforms/linux/utilities/rar/","text":"RAR rar - Archive files in rar format. unrar - Extract files from rar archives. Create an archive rar COMMAND ARCHIVE r - Repair archive t - Test archive files p - Print file to stdout a - Add files to archive u - Update files in archive l - List content of archive d - Delete files from archive e - Extract files to current directory (no subdirectories) Extract an archive unrar COMMAND ARCHIVE t - Test archive files l - List archive content p - Print file to stdout v - Verbosely list archive x - Extract files with full path e - Extract files to current directory","title":"rar"},{"location":"dev/Platforms/linux/utilities/rar/#rar","text":"rar - Archive files in rar format. unrar - Extract files from rar archives. Create an archive rar COMMAND ARCHIVE r - Repair archive t - Test archive files p - Print file to stdout a - Add files to archive u - Update files in archive l - List content of archive d - Delete files from archive e - Extract files to current directory (no subdirectories) Extract an archive unrar COMMAND ARCHIVE t - Test archive files l - List archive content p - Print file to stdout v - Verbosely list archive x - Extract files with full path e - Extract files to current directory","title":"RAR"},{"location":"dev/Platforms/linux/utilities/sort/","text":"SORT sort lines of text files. sort [OPTION] [FILE] ORDERING OPTIONS: -r, --reverse - reverse the result of comparisons -b, --ignore-leading-blanks - ignore leading blanks -R, --random-sort - shuffle, but group identical keys -f, --ignore-case - fold lower case to upper case characters -i, --ignore-nonprinting - consider only printable characters -n, --numeric-sort - compare according to string numerical value -V, --version-sort - natural sort of (version) numbers within text -h, --human-numeric-sort - compare human readable numbers (e.g., 2K 1G) -d, --dictionary-order - consider only blanks and alphanumeric characters -g, --general-numeric-sort - compare according to general numerical value --sort=WORD - sort according to WORD: general-numeric -g, human-numeric -h, month -M, numeric -n, random -R, version -V","title":"sort"},{"location":"dev/Platforms/linux/utilities/sort/#sort","text":"sort lines of text files. sort [OPTION] [FILE]","title":"SORT"},{"location":"dev/Platforms/linux/utilities/sort/#ordering-options","text":"-r, --reverse - reverse the result of comparisons -b, --ignore-leading-blanks - ignore leading blanks -R, --random-sort - shuffle, but group identical keys -f, --ignore-case - fold lower case to upper case characters -i, --ignore-nonprinting - consider only printable characters -n, --numeric-sort - compare according to string numerical value -V, --version-sort - natural sort of (version) numbers within text -h, --human-numeric-sort - compare human readable numbers (e.g., 2K 1G) -d, --dictionary-order - consider only blanks and alphanumeric characters -g, --general-numeric-sort - compare according to general numerical value --sort=WORD - sort according to WORD: general-numeric -g, human-numeric -h, month -M, numeric -n, random -R, version -V","title":"ORDERING OPTIONS:"},{"location":"dev/Platforms/linux/utilities/tar/","text":"TAR The tar command creates and manipulates streaming archive files. Create an uncompressed tar archive tar cvf ARCHIVE.tar DIRECTORY c - Create a new archive v - Verbosely list files f - Follow archive file name Create a tar gzipped archive tar cvfz ARCHIVE.tar.gz DIRECTORY z - Filter the archive through gzip Create a bzipped (bzip2) tar archive tar cvfj ARCHIVE.tar.bz2 DIRECTORY j - Filter the archive through bzip2 N.B. bzip2 takes more time to compress and decompress than gzip but requires less space. Extract a .tar archive tar xvf ARCHIVE.tar x - Extract files from archive Extract a gzipped | bzipped tar archive tar xvfz ARCHIVE.tar.gz tar xvfj ARCHIVE.tar.bz2 List the contents of an archive tar tvf ARCHIVE.tar tar tvfz ARCHIVE.tar.gz tar tvfj ARCHIVE.tar.bz2 Extract a single file or directory tar xvf ARCHIVE.tar <PATH> Append a file or directory to an existing archive tar rvf ARCHIVE.tar <PATH> r - Append files to the end of an archive","title":"tar"},{"location":"dev/Platforms/linux/utilities/tar/#tar","text":"The tar command creates and manipulates streaming archive files. Create an uncompressed tar archive tar cvf ARCHIVE.tar DIRECTORY c - Create a new archive v - Verbosely list files f - Follow archive file name Create a tar gzipped archive tar cvfz ARCHIVE.tar.gz DIRECTORY z - Filter the archive through gzip Create a bzipped (bzip2) tar archive tar cvfj ARCHIVE.tar.bz2 DIRECTORY j - Filter the archive through bzip2 N.B. bzip2 takes more time to compress and decompress than gzip but requires less space. Extract a .tar archive tar xvf ARCHIVE.tar x - Extract files from archive Extract a gzipped | bzipped tar archive tar xvfz ARCHIVE.tar.gz tar xvfj ARCHIVE.tar.bz2 List the contents of an archive tar tvf ARCHIVE.tar tar tvfz ARCHIVE.tar.gz tar tvfj ARCHIVE.tar.bz2 Extract a single file or directory tar xvf ARCHIVE.tar <PATH> Append a file or directory to an existing archive tar rvf ARCHIVE.tar <PATH> r - Append files to the end of an archive","title":"TAR"},{"location":"dev/Platforms/linux/utilities/unar/","text":"UNAR Command-line unarchiving tools supporting multiple formats Extract an archive unar [OPTION] ARCHIVE -q - Run in quiet mode -o - Directory where to write the content -s - Skip file when already exists on disk -d - Create a containing directory for archive content -f - Overwrite when a file to be unpacked already exists","title":"unar"},{"location":"dev/Platforms/linux/utilities/unar/#unar","text":"Command-line unarchiving tools supporting multiple formats Extract an archive unar [OPTION] ARCHIVE -q - Run in quiet mode -o - Directory where to write the content -s - Skip file when already exists on disk -d - Create a containing directory for archive content -f - Overwrite when a file to be unpacked already exists","title":"UNAR"},{"location":"dev/Platforms/linux/utilities/uniq/","text":"UNIQ The uniq command report or omit repeated lines. With no options, matching lines are merged to the first occurrence. uniq [OPTION] INPUT -c - prefix lines by the number of occurrences -d - only print duplicate lines, one for each group -D - print all duplicate lines -i - ignore differences in case when comparing -u - only print unique lines","title":"uniq"},{"location":"dev/Platforms/linux/utilities/uniq/#uniq","text":"The uniq command report or omit repeated lines. With no options, matching lines are merged to the first occurrence. uniq [OPTION] INPUT -c - prefix lines by the number of occurrences -d - only print duplicate lines, one for each group -D - print all duplicate lines -i - ignore differences in case when comparing -u - only print unique lines","title":"UNIQ"},{"location":"dev/Platforms/linux/utilities/zip/","text":"ZIP The zip / unzip commands package, compress and decompress archive files Create an archive zip -r ARCHIVE FOLDER | FILE r - Travel the directory structure recursively Delete entries from a zip archive zip -d ARCHIVE TO_DELETE List files in an archive unzip -l ARCHIVE Extract a zip archive unzip ARCHIVE","title":"zip"},{"location":"dev/Platforms/linux/utilities/zip/#zip","text":"The zip / unzip commands package, compress and decompress archive files Create an archive zip -r ARCHIVE FOLDER | FILE r - Travel the directory structure recursively Delete entries from a zip archive zip -d ARCHIVE TO_DELETE List files in an archive unzip -l ARCHIVE Extract a zip archive unzip ARCHIVE","title":"ZIP"},{"location":"dev/Tools/docker/","text":"Docker How to manage containers Start a container docker run IMAGE[:TAG] Start a container in detached mode docker run -d IMAGE[:TAG] Start a container in interactive mode docker run -i IMAGE[:TAG] Start a container in interactive mode with a pseudo-tty docker run -it IMAGE[:TAG] Start a container with an environmental variable docker run -e VARIABLE=VALUE IMAGE[:TAG] Attach to a running container docker attach ID docker attach NAME Append a command to a container docker run CONTAINER COMMAND Execute a command in a container docker exec ID COMMAND docker exec NAME COMMAND List containers docker ps docker ps -a (to list all containers) docker container ls Inspect a container docker inspect ID docker inspect NAME Inspect container's logs docker logs ID docker logs NAME Stop a container docker stop ID docker stop NAME Remove a container docker rm ID docker rm NAME How to manage images Build an image from a Dockerfile docker build -f DOCKERFILE docker build [OPTIONS] URL docker build [OPTIONS] PATH docker build PATH_TO_DOCKERFILE (file must be called \"Dockerfile\") Build and tag an image from a Dockerfile docker build -t REPOSITORY/IMAGE[:TAG] DOCKERFILE List images docker images docker image ls Tag a new image docker tag ID REPOSITORY/IMAGE/TAG docker tag IMAGE REPOSITORY/IMAGE/TAG docker tag IMAGE[:TAG] REPOSITORY/IMAGE/TAG docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE<:TAG> Push an image to a registry (e.g. DockerHub) docker push ACCOUNT/IMAGE[:TAG] docker push REGISTRY:PORT/LOCATION/IMAGE[:TAG] Pull down an image docker pull IMAGE[:TAG] docker pull REGISTRY:PORT/LOCATION/IMAGE[:TAG] Remove an image docker rmi NAME[:TAG] Network configuration Running an isolated container docker run IMAGE --network=none Running a container associated with Docker-host network docker run IMAGE --network=host Create a new network docker network create [OPTIONS] NETWORK Network options Name Description --attachable Enable manual container attachment (API 1.25+) --driver , -d Driver to manage the Network (default: bridge) --gateway IPv4 or IPv6 Gateway for the master subnet --internal Restrict external access to the network --ip-range Allocate container ip from a sub-range --ipv6 Enable IPv6 networking --scope Control the network's scope (API 1.30+) --subnet Subnet in CIDR format that represents a network segment List networks docker network ls Inspect a network docker network inspect NETWORK Remove a network docker network rm NETWORK PORT mapping docker run -p DOCKER_PORT:CONTAINER_PORT IMAGE[:TAG] docker run -p DOCKER_PORT/PROTOCOL:CONTAINER_PORT/PROTOCOL IMAGE[:TAG] docker run -p DOCKER_IP:DOCKER_PORT/PROTOCOL:CONTAINER_PORT/PROTOCOL IMAGE[:TAG] Storage configuration Create a volume docker volume create NAME Remove a volume docker volume rm NAME List volumes docker volume ls Inspect a volume docker volume inspect NAME Volume mapping docker run -v VOLUME:MOUNTPOINT:OPTIONS IMAGE[:TAG] docker run -v LOCAL_PATH:MOUNTPOINT:OPTIONS IMAGE[:TAG] Dockerfile Dockerfile format # Comment INSTRUCTION arguments The FROM instruction initializes a new build stage and sets the base image. FROM [--platform=<platform>] image[:<tag>] [AS <name>] The RUN instruction will execute any commands in a new layer on top of the current image ad commit the results. RUN <command> RUN [\"executable\", \"param1\", \"param2\"] The main purpose of a CMD is to provide defaults for an executing container. These defaults can include an executable, or they can omit the executable, in which case you must specify an ENTRYPOINT instruction as well. There can only be one CMD instruction in a Dockerfile, so if you list more than one CMD then only the last CMD will take effect. CMD <command> <param1> <param2> CMD [\"param1\",\"param2\"] (parameters to ENTRYPOINT) CMD [\"executable\",\"param1\",\"param2\"] The LABEL instruction adds metadata to an image. A LABEL is a key-value pair. To include spaces within a LABEL value, use quotes and backslashes as you would in command-line parsing. LABEL <key>=<value> <key>=<value> ... The ENV instruction sets the environment variable \"key\" to the value \"value\". This value will be in the environment for all subsequent instructions in the build stage and can be replaced inline in many as well. The value will be interpreted for other environment variables, so quote characters will be removed if they are not escaped. ENV <key>=<value> <key>=<value> ... The ADD instruction copies new files, directories or remote file URLs from \"src\" and adds them to the filesystem of the image at the path \"dest\". Multiple \"src\"resources may be specified but if they are files or directories, their paths are interpreted as relative to the source of the context of the build. The --chown feature is only supported on Dockerfiles used to build Linux containers. ADD [--chown=<user>:<group>] <src>... <dest> The COPY instruction copies new files or directories from \"src\" and adds them to the filesystem of the container at the path \"dest\". Multiple \"src\" resources may be specified but the paths of files and directories will be interpreted as relative to the source of the context of the build. The --chown feature is only supported on Dockerfiles used to build Linux containers. COPY [--chown=<user>:<group>] <src>... <dest> An ENTRYPOINT allows you to configure a container that will run as an executable. ENTRYPOINT command param1 param2 ENTRYPOINT [\"executable\", \"param1\", \"param2\"] The VOLUME instruction creates a mount point with the specified name and marks it as holding externally mounted volumes from native host or other containers. The value can be a JSON array, VOLUME [\"/var/log/\"], or a plain string with multiple arguments, such as VOLUME /var/log or VOLUME /var/log /var/db. The docker run command initializes the newly created volume with any data that exists at the specified location within the base image. VOLUME <path> <path> ... VOLUME [\"<path>\"] The USER instruction sets the user name (or UID) and optionally the user group (or GID) to use when running the image and for any RUN, CMD and ENTRYPOINT instructions that follow it in the Dockerfile. USER <UID>[:<GID>] USER <user>[:<group>] The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile. If the WORKDIR doesn\u2019t exist, it will be created even if it\u2019s not used in any subsequent Dockerfile instruction. The WORKDIR instruction can be used multiple times in a Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. WORKDIR </path_to_workdir> The ARG instruction defines a variable that users can pass at build-time to the builder with the docker build command using the --build-arg varname=\"value\" flag. If a user specifies a build argument that was not defined in the Dockerfile, the build outputs a warning. ARG <name>[=<default value>] The ONBUILD instruction adds to the image a trigger instruction to be executed at a later time, when the image is used as the base for another build. The trigger will be executed in the context of the downstream build, as if it had been inserted immediately after the FROM instruction in the downstream Dockerfile. ONBUILD <INSTRUCTION> The STOPSIGNAL instruction sets the system call signal that will be sent to the container to exit. This signal can be a signal name in the format SIGNAME, for instance SIGKILL, or an unsigned number that matches a position in the kernel\u2019s syscall table, for instance 9. The default is SIGTERM if not defined. STOPSIGNAL signal The HEALTHCHECK instruction tells Docker how to test a container to check that it is still working. This can detect cases such as a web server that is stuck in an infinite loop and unable to handle new connections, even though the server process is still running. When a container has a healthcheck specified, it has a health status in addition to its normal status. This status is initially starting. Whenever a health check passes, it becomes healthy (whatever state it was previously in). After a certain number of consecutive failures, it becomes unhealthy. HEALTHCHECK NONE (disable any healthcheck inherited) HEALTHCHECK [OPTIONS] CMD command (check container health by running a command) The options that can appear before CMD are: - --retries=N (default: 3) - --timeout=DURATION (default: 30s) - --interval=DURATION (default: 30s) - --start-period=DURATION (default: 0s) The SHELL instruction allows the default shell used for the shell form of commands to be overridden. The default shell on Linux is [\"/bin/sh\", \"-c\"], and on Windows is [\"cmd\", \"/S\", \"/C\"]. The SHELL instruction must be written in JSON form in a Dockerfile. SHELL [\"executable\", \"parameters\"]","title":"Docker"},{"location":"dev/Tools/docker/#docker","text":"","title":"Docker"},{"location":"dev/Tools/docker/#how-to-manage-containers","text":"Start a container docker run IMAGE[:TAG] Start a container in detached mode docker run -d IMAGE[:TAG] Start a container in interactive mode docker run -i IMAGE[:TAG] Start a container in interactive mode with a pseudo-tty docker run -it IMAGE[:TAG] Start a container with an environmental variable docker run -e VARIABLE=VALUE IMAGE[:TAG] Attach to a running container docker attach ID docker attach NAME Append a command to a container docker run CONTAINER COMMAND Execute a command in a container docker exec ID COMMAND docker exec NAME COMMAND List containers docker ps docker ps -a (to list all containers) docker container ls Inspect a container docker inspect ID docker inspect NAME Inspect container's logs docker logs ID docker logs NAME Stop a container docker stop ID docker stop NAME Remove a container docker rm ID docker rm NAME","title":"How to manage containers"},{"location":"dev/Tools/docker/#how-to-manage-images","text":"Build an image from a Dockerfile docker build -f DOCKERFILE docker build [OPTIONS] URL docker build [OPTIONS] PATH docker build PATH_TO_DOCKERFILE (file must be called \"Dockerfile\") Build and tag an image from a Dockerfile docker build -t REPOSITORY/IMAGE[:TAG] DOCKERFILE List images docker images docker image ls Tag a new image docker tag ID REPOSITORY/IMAGE/TAG docker tag IMAGE REPOSITORY/IMAGE/TAG docker tag IMAGE[:TAG] REPOSITORY/IMAGE/TAG docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE<:TAG> Push an image to a registry (e.g. DockerHub) docker push ACCOUNT/IMAGE[:TAG] docker push REGISTRY:PORT/LOCATION/IMAGE[:TAG] Pull down an image docker pull IMAGE[:TAG] docker pull REGISTRY:PORT/LOCATION/IMAGE[:TAG] Remove an image docker rmi NAME[:TAG]","title":"How to manage images"},{"location":"dev/Tools/docker/#network-configuration","text":"Running an isolated container docker run IMAGE --network=none Running a container associated with Docker-host network docker run IMAGE --network=host Create a new network docker network create [OPTIONS] NETWORK Network options Name Description --attachable Enable manual container attachment (API 1.25+) --driver , -d Driver to manage the Network (default: bridge) --gateway IPv4 or IPv6 Gateway for the master subnet --internal Restrict external access to the network --ip-range Allocate container ip from a sub-range --ipv6 Enable IPv6 networking --scope Control the network's scope (API 1.30+) --subnet Subnet in CIDR format that represents a network segment List networks docker network ls Inspect a network docker network inspect NETWORK Remove a network docker network rm NETWORK PORT mapping docker run -p DOCKER_PORT:CONTAINER_PORT IMAGE[:TAG] docker run -p DOCKER_PORT/PROTOCOL:CONTAINER_PORT/PROTOCOL IMAGE[:TAG] docker run -p DOCKER_IP:DOCKER_PORT/PROTOCOL:CONTAINER_PORT/PROTOCOL IMAGE[:TAG]","title":"Network configuration"},{"location":"dev/Tools/docker/#storage-configuration","text":"Create a volume docker volume create NAME Remove a volume docker volume rm NAME List volumes docker volume ls Inspect a volume docker volume inspect NAME Volume mapping docker run -v VOLUME:MOUNTPOINT:OPTIONS IMAGE[:TAG] docker run -v LOCAL_PATH:MOUNTPOINT:OPTIONS IMAGE[:TAG]","title":"Storage configuration"},{"location":"dev/Tools/docker/#dockerfile","text":"Dockerfile format # Comment INSTRUCTION arguments The FROM instruction initializes a new build stage and sets the base image. FROM [--platform=<platform>] image[:<tag>] [AS <name>] The RUN instruction will execute any commands in a new layer on top of the current image ad commit the results. RUN <command> RUN [\"executable\", \"param1\", \"param2\"] The main purpose of a CMD is to provide defaults for an executing container. These defaults can include an executable, or they can omit the executable, in which case you must specify an ENTRYPOINT instruction as well. There can only be one CMD instruction in a Dockerfile, so if you list more than one CMD then only the last CMD will take effect. CMD <command> <param1> <param2> CMD [\"param1\",\"param2\"] (parameters to ENTRYPOINT) CMD [\"executable\",\"param1\",\"param2\"] The LABEL instruction adds metadata to an image. A LABEL is a key-value pair. To include spaces within a LABEL value, use quotes and backslashes as you would in command-line parsing. LABEL <key>=<value> <key>=<value> ... The ENV instruction sets the environment variable \"key\" to the value \"value\". This value will be in the environment for all subsequent instructions in the build stage and can be replaced inline in many as well. The value will be interpreted for other environment variables, so quote characters will be removed if they are not escaped. ENV <key>=<value> <key>=<value> ... The ADD instruction copies new files, directories or remote file URLs from \"src\" and adds them to the filesystem of the image at the path \"dest\". Multiple \"src\"resources may be specified but if they are files or directories, their paths are interpreted as relative to the source of the context of the build. The --chown feature is only supported on Dockerfiles used to build Linux containers. ADD [--chown=<user>:<group>] <src>... <dest> The COPY instruction copies new files or directories from \"src\" and adds them to the filesystem of the container at the path \"dest\". Multiple \"src\" resources may be specified but the paths of files and directories will be interpreted as relative to the source of the context of the build. The --chown feature is only supported on Dockerfiles used to build Linux containers. COPY [--chown=<user>:<group>] <src>... <dest> An ENTRYPOINT allows you to configure a container that will run as an executable. ENTRYPOINT command param1 param2 ENTRYPOINT [\"executable\", \"param1\", \"param2\"] The VOLUME instruction creates a mount point with the specified name and marks it as holding externally mounted volumes from native host or other containers. The value can be a JSON array, VOLUME [\"/var/log/\"], or a plain string with multiple arguments, such as VOLUME /var/log or VOLUME /var/log /var/db. The docker run command initializes the newly created volume with any data that exists at the specified location within the base image. VOLUME <path> <path> ... VOLUME [\"<path>\"] The USER instruction sets the user name (or UID) and optionally the user group (or GID) to use when running the image and for any RUN, CMD and ENTRYPOINT instructions that follow it in the Dockerfile. USER <UID>[:<GID>] USER <user>[:<group>] The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile. If the WORKDIR doesn\u2019t exist, it will be created even if it\u2019s not used in any subsequent Dockerfile instruction. The WORKDIR instruction can be used multiple times in a Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. WORKDIR </path_to_workdir> The ARG instruction defines a variable that users can pass at build-time to the builder with the docker build command using the --build-arg varname=\"value\" flag. If a user specifies a build argument that was not defined in the Dockerfile, the build outputs a warning. ARG <name>[=<default value>] The ONBUILD instruction adds to the image a trigger instruction to be executed at a later time, when the image is used as the base for another build. The trigger will be executed in the context of the downstream build, as if it had been inserted immediately after the FROM instruction in the downstream Dockerfile. ONBUILD <INSTRUCTION> The STOPSIGNAL instruction sets the system call signal that will be sent to the container to exit. This signal can be a signal name in the format SIGNAME, for instance SIGKILL, or an unsigned number that matches a position in the kernel\u2019s syscall table, for instance 9. The default is SIGTERM if not defined. STOPSIGNAL signal The HEALTHCHECK instruction tells Docker how to test a container to check that it is still working. This can detect cases such as a web server that is stuck in an infinite loop and unable to handle new connections, even though the server process is still running. When a container has a healthcheck specified, it has a health status in addition to its normal status. This status is initially starting. Whenever a health check passes, it becomes healthy (whatever state it was previously in). After a certain number of consecutive failures, it becomes unhealthy. HEALTHCHECK NONE (disable any healthcheck inherited) HEALTHCHECK [OPTIONS] CMD command (check container health by running a command) The options that can appear before CMD are: - --retries=N (default: 3) - --timeout=DURATION (default: 30s) - --interval=DURATION (default: 30s) - --start-period=DURATION (default: 0s) The SHELL instruction allows the default shell used for the shell form of commands to be overridden. The default shell on Linux is [\"/bin/sh\", \"-c\"], and on Windows is [\"cmd\", \"/S\", \"/C\"]. The SHELL instruction must be written in JSON form in a Dockerfile. SHELL [\"executable\", \"parameters\"]","title":"Dockerfile"},{"location":"sec/Frameworks/ATT%26CK/","text":"MITRE ATT&CK MITRE ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge) is a comprehensive framework and knowledge base that provides information about the tactics, techniques, and procedures (TTPs) that cyber adversaries use during different stages of a cyber attack. It was developed by MITRE to help cybersecurity professionals and organizations understand and defend against real-world cyber threats more effectively. The ATT&CK framework is organized into matrices that cover different platforms, such as Windows, macOS, Linux, cloud environments, and mobile devices. Each matrix is divided into rows (tactics) and columns (techniques). Here's how it works: Tactics - Tactics represent the high-level goals that attackers aim to achieve during a cyber attack. Examples of tactics include Initial Access, Execution, Persistence, Privilege Escalation, Defense Evasion, Credential Access, Discovery, Lateral Movement, Collection, Exfiltration, and Impact. These tactics are the stages of a typical attack lifecycle. Techniques - Techniques are the specific methods or actions that attackers use to accomplish the goals outlined in the tactics. Each technique describes a step or action taken by an attacker to achieve a specific objective. For instance, within the Execution tactic, there could be techniques like \"Command-Line Interface\" and \"Scripting.\" Procedure Examples - For each technique, MITRE provides real-world examples of how attackers have used that technique in actual cyber attacks. These examples help provide context and insights into how attackers operate. Mitigations - Alongside the techniques, MITRE also provides information about potential mitigations that organizations can implement to defend against or prevent those techniques. These mitigations can help organizations strengthen their security posture. Groups and Software - The ATT&CK framework also associates techniques with known threat actor groups and specific malware or tools they have used. This provides information about the adversaries associated with each technique and helps organizations understand the threat landscape. Data Sources - For each technique, ATT&CK suggests the types of data sources (logs, events, etc.) that organizations can monitor to detect and respond to that technique's use. By using the ATT&CK framework, organizations can: Improve Detection and Response - By understanding the techniques used by adversaries, organizations can develop more effective strategies to detect and respond to cyber threats. Enhance Threat Intelligence - ATT&CK provides a standardized way to describe and share threat intelligence, making it easier for organizations to collaborate and share insights about emerging threats. Evaluate Security Tools - Organizations can use ATT&CK to assess how well their security tools and technologies cover various attack techniques. This helps in selecting and optimizing security solutions. Train Security Professionals - ATT&CK can be used to train security professionals and help them understand the tactics and techniques that attackers might employ.","title":"ATT&CK"},{"location":"sec/Frameworks/ATT%26CK/#mitre-attck","text":"MITRE ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge) is a comprehensive framework and knowledge base that provides information about the tactics, techniques, and procedures (TTPs) that cyber adversaries use during different stages of a cyber attack. It was developed by MITRE to help cybersecurity professionals and organizations understand and defend against real-world cyber threats more effectively. The ATT&CK framework is organized into matrices that cover different platforms, such as Windows, macOS, Linux, cloud environments, and mobile devices. Each matrix is divided into rows (tactics) and columns (techniques). Here's how it works: Tactics - Tactics represent the high-level goals that attackers aim to achieve during a cyber attack. Examples of tactics include Initial Access, Execution, Persistence, Privilege Escalation, Defense Evasion, Credential Access, Discovery, Lateral Movement, Collection, Exfiltration, and Impact. These tactics are the stages of a typical attack lifecycle. Techniques - Techniques are the specific methods or actions that attackers use to accomplish the goals outlined in the tactics. Each technique describes a step or action taken by an attacker to achieve a specific objective. For instance, within the Execution tactic, there could be techniques like \"Command-Line Interface\" and \"Scripting.\" Procedure Examples - For each technique, MITRE provides real-world examples of how attackers have used that technique in actual cyber attacks. These examples help provide context and insights into how attackers operate. Mitigations - Alongside the techniques, MITRE also provides information about potential mitigations that organizations can implement to defend against or prevent those techniques. These mitigations can help organizations strengthen their security posture. Groups and Software - The ATT&CK framework also associates techniques with known threat actor groups and specific malware or tools they have used. This provides information about the adversaries associated with each technique and helps organizations understand the threat landscape. Data Sources - For each technique, ATT&CK suggests the types of data sources (logs, events, etc.) that organizations can monitor to detect and respond to that technique's use. By using the ATT&CK framework, organizations can: Improve Detection and Response - By understanding the techniques used by adversaries, organizations can develop more effective strategies to detect and respond to cyber threats. Enhance Threat Intelligence - ATT&CK provides a standardized way to describe and share threat intelligence, making it easier for organizations to collaborate and share insights about emerging threats. Evaluate Security Tools - Organizations can use ATT&CK to assess how well their security tools and technologies cover various attack techniques. This helps in selecting and optimizing security solutions. Train Security Professionals - ATT&CK can be used to train security professionals and help them understand the tactics and techniques that attackers might employ.","title":"MITRE ATT&amp;CK"},{"location":"sec/Frameworks/CIS/","text":"Center for Internet Security The Center for Internet Security (CIS) is a nonprofit organization that focuses on enhancing the cybersecurity readiness and response of public and private sector entities. CIS was established in 2000 with the aim of providing resources, tools, and best practices to help organizations defend against cyber threats and vulnerabilities. CIS offers a variety of services and initiatives, including: CIS Controls and CIS Benchmarks: These are sets of best practices and guidelines for securing IT systems and data. The CIS Controls provide a prioritized framework to improve an organization's cybersecurity posture, while the CIS Benchmarks offer specific configuration guidelines for various operating systems, software, and network devices. CIS-CAT Pro: This is a tool that helps organizations assess and implement the CIS Benchmarks effectively. It provides automated assessment and compliance capabilities to ensure systems are properly configured and secure. CIS SecureSuite Membership: This membership provides access to various cybersecurity tools, resources, and guidance, including the CIS Benchmarks, CIS Controls, and other security solutions. CIS CyberMarket: An online platform that offers a curated selection of cybersecurity products and services that align with the CIS Controls and Benchmarks. CIS-CERT: The CIS Cybersecurity Emergency Response Team provides assistance to organizations during cyber incidents, offering expertise and guidance to help mitigate the impact of cyber threats. Training and Certification: CIS provides training courses and certifications to help individuals and organizations develop their cybersecurity skills and knowledge. Research and Publications: CIS conducts research on emerging cybersecurity threats and trends, and publishes reports and whitepapers to share insights and recommendations with the cybersecurity community. Public-Private Partnerships: CIS collaborates with government agencies, private sector organizations, and international partners to promote cybersecurity awareness and resilience on a global scale.","title":"CIS"},{"location":"sec/Frameworks/CIS/#center-for-internet-security","text":"The Center for Internet Security (CIS) is a nonprofit organization that focuses on enhancing the cybersecurity readiness and response of public and private sector entities. CIS was established in 2000 with the aim of providing resources, tools, and best practices to help organizations defend against cyber threats and vulnerabilities. CIS offers a variety of services and initiatives, including: CIS Controls and CIS Benchmarks: These are sets of best practices and guidelines for securing IT systems and data. The CIS Controls provide a prioritized framework to improve an organization's cybersecurity posture, while the CIS Benchmarks offer specific configuration guidelines for various operating systems, software, and network devices. CIS-CAT Pro: This is a tool that helps organizations assess and implement the CIS Benchmarks effectively. It provides automated assessment and compliance capabilities to ensure systems are properly configured and secure. CIS SecureSuite Membership: This membership provides access to various cybersecurity tools, resources, and guidance, including the CIS Benchmarks, CIS Controls, and other security solutions. CIS CyberMarket: An online platform that offers a curated selection of cybersecurity products and services that align with the CIS Controls and Benchmarks. CIS-CERT: The CIS Cybersecurity Emergency Response Team provides assistance to organizations during cyber incidents, offering expertise and guidance to help mitigate the impact of cyber threats. Training and Certification: CIS provides training courses and certifications to help individuals and organizations develop their cybersecurity skills and knowledge. Research and Publications: CIS conducts research on emerging cybersecurity threats and trends, and publishes reports and whitepapers to share insights and recommendations with the cybersecurity community. Public-Private Partnerships: CIS collaborates with government agencies, private sector organizations, and international partners to promote cybersecurity awareness and resilience on a global scale.","title":"Center for Internet Security"},{"location":"sec/Frameworks/CSA/","text":"Cloud Security Alliance The Cloud Security Alliance (CSA) is a non-profit organization focused on promoting and ensuring security in cloud computing environments. It was founded in 2008 and has since become a leading authority on cloud security best practices, education, and research. The main objectives of the Cloud Security Alliance include: Promoting Best Practices: The CSA works to develop and promote best practices, guidelines, and standards for securing various aspects of cloud computing, including data protection, identity and access management, compliance, and more. Educational Initiatives: The CSA offers educational resources, training, and certification programs to help individuals and organizations understand and implement effective cloud security measures. Research and Collaboration: The CSA conducts research on emerging threats, vulnerabilities, and trends in cloud security. It collaborates with industry experts, researchers, and practitioners to provide valuable insights into the evolving landscape of cloud security. Advocacy and Awareness: The CSA advocates for cloud security awareness and encourages businesses to prioritize security when adopting and using cloud services. It also engages with policymakers and regulatory bodies to influence the development of cloud security-related regulations and standards. Community Building: The CSA fosters a global community of professionals, vendors, researchers, and organizations interested in cloud security. This community collaborates to share knowledge, experiences, and solutions for addressing cloud security challenges. One of the most well-known contributions from the CSA is the \" Cloud Controls Matrix (CCM) \", which provides a comprehensive framework for assessing the security controls available in various cloud services. This matrix helps organizations evaluate the security capabilities of different cloud providers and choose the one that aligns with their security requirements.","title":"CSA"},{"location":"sec/Frameworks/CSA/#cloud-security-alliance","text":"The Cloud Security Alliance (CSA) is a non-profit organization focused on promoting and ensuring security in cloud computing environments. It was founded in 2008 and has since become a leading authority on cloud security best practices, education, and research. The main objectives of the Cloud Security Alliance include: Promoting Best Practices: The CSA works to develop and promote best practices, guidelines, and standards for securing various aspects of cloud computing, including data protection, identity and access management, compliance, and more. Educational Initiatives: The CSA offers educational resources, training, and certification programs to help individuals and organizations understand and implement effective cloud security measures. Research and Collaboration: The CSA conducts research on emerging threats, vulnerabilities, and trends in cloud security. It collaborates with industry experts, researchers, and practitioners to provide valuable insights into the evolving landscape of cloud security. Advocacy and Awareness: The CSA advocates for cloud security awareness and encourages businesses to prioritize security when adopting and using cloud services. It also engages with policymakers and regulatory bodies to influence the development of cloud security-related regulations and standards. Community Building: The CSA fosters a global community of professionals, vendors, researchers, and organizations interested in cloud security. This community collaborates to share knowledge, experiences, and solutions for addressing cloud security challenges. One of the most well-known contributions from the CSA is the \" Cloud Controls Matrix (CCM) \", which provides a comprehensive framework for assessing the security controls available in various cloud services. This matrix helps organizations evaluate the security capabilities of different cloud providers and choose the one that aligns with their security requirements.","title":"Cloud Security Alliance"},{"location":"sec/Frameworks/CyberKillChain/","text":"The Cyber Kill Chain The Cyber Kill Chain framework is a model for identification and prevention of cyber intrusions activity. The model identifies what the adversaries must complete in order to achieve their objective. To succeed, an adversary needs to go through all phases of the Kill Chain. Reconnaissance - Reconnaissance is discovering and collecting information on the system and the victim. The reconnaissance phase is the planning phase for the adversaries. OSINT is the first step an attacker needs to complete to carry out the further phases of an attack. The attacker needs to study the victim by collecting every available piece of information on the company and its employees, such as the company's size, email addresses, phone numbers from publicly available resources to determine the best target for the attack. Weaponization - In the weaponization stage, all of the attacker\u2019s preparatory work culminates in the creation of malware to be used against an identified target. Weaponization can include creating new types of malware or modifying existing tools to use in a cyberattack. Delivery - In the delivery stage, cyberweapons and other Cyber Kill Chain tools are used to infiltrate a target\u2019s network and reach users. Delivery may involve sending phishing emails containing malware attachments with subject lines that prompt users to click through. Delivery can also take the form of hacking into an organization\u2019s network and exploiting a hardware or software vulnerability to infiltrate it. Exploitation - In the exploitation step of the Cyber Kill Chain, attackers take advantage of the vulnerabilities they have discovered in previous stages to further infiltrate a target\u2019s network and achieve their objectives. In this process, cybercriminals often move laterally across a network to reach their targets. Installation - After cybercriminals have exploited their target\u2019s vulnerabilities to gain access to a network, they begin the installation stage of the Cyber Kill Chain: attempting to install malware and other cyberweapons onto the target network to take control of its systems and exfiltrate valuable data. In this step, cybercriminals may install cyberweapons and malware using Trojan horses, backdoors, or command-line interfaces. Command and Control - In the C2 stage of the Cyber Kill Chain, cybercriminals communicate with the malware they\u2019ve installed onto a target\u2019s network to instruct cyberweapons or tools to carry out their objectives. Actions on Objectives - After cybercriminals have developed cyberweapons, installed them onto a target\u2019s network, and taken control of their target\u2019s network, they begin the final stage of the Cyber Kill Chain: carrying out their cyberattack objectives. While cybercriminals\u2019 objectives vary depending on the type of cyberattack, some examples include weaponizing a botnet to interrupt services with a Distributed Denial of Service (DDoS) attack, distributing malware to steal sensitive data from a target organization, and using ransomware as a cyber extortion tool.","title":"CyberKillChain"},{"location":"sec/Frameworks/CyberKillChain/#the-cyber-kill-chain","text":"The Cyber Kill Chain framework is a model for identification and prevention of cyber intrusions activity. The model identifies what the adversaries must complete in order to achieve their objective. To succeed, an adversary needs to go through all phases of the Kill Chain. Reconnaissance - Reconnaissance is discovering and collecting information on the system and the victim. The reconnaissance phase is the planning phase for the adversaries. OSINT is the first step an attacker needs to complete to carry out the further phases of an attack. The attacker needs to study the victim by collecting every available piece of information on the company and its employees, such as the company's size, email addresses, phone numbers from publicly available resources to determine the best target for the attack. Weaponization - In the weaponization stage, all of the attacker\u2019s preparatory work culminates in the creation of malware to be used against an identified target. Weaponization can include creating new types of malware or modifying existing tools to use in a cyberattack. Delivery - In the delivery stage, cyberweapons and other Cyber Kill Chain tools are used to infiltrate a target\u2019s network and reach users. Delivery may involve sending phishing emails containing malware attachments with subject lines that prompt users to click through. Delivery can also take the form of hacking into an organization\u2019s network and exploiting a hardware or software vulnerability to infiltrate it. Exploitation - In the exploitation step of the Cyber Kill Chain, attackers take advantage of the vulnerabilities they have discovered in previous stages to further infiltrate a target\u2019s network and achieve their objectives. In this process, cybercriminals often move laterally across a network to reach their targets. Installation - After cybercriminals have exploited their target\u2019s vulnerabilities to gain access to a network, they begin the installation stage of the Cyber Kill Chain: attempting to install malware and other cyberweapons onto the target network to take control of its systems and exfiltrate valuable data. In this step, cybercriminals may install cyberweapons and malware using Trojan horses, backdoors, or command-line interfaces. Command and Control - In the C2 stage of the Cyber Kill Chain, cybercriminals communicate with the malware they\u2019ve installed onto a target\u2019s network to instruct cyberweapons or tools to carry out their objectives. Actions on Objectives - After cybercriminals have developed cyberweapons, installed them onto a target\u2019s network, and taken control of their target\u2019s network, they begin the final stage of the Cyber Kill Chain: carrying out their cyberattack objectives. While cybercriminals\u2019 objectives vary depending on the type of cyberattack, some examples include weaponizing a botnet to interrupt services with a Distributed Denial of Service (DDoS) attack, distributing malware to steal sensitive data from a target organization, and using ransomware as a cyber extortion tool.","title":"The Cyber Kill Chain"},{"location":"sec/Frameworks/DiamondModel/","text":"The Diamond Model The Diamond Model of Intrusion Analysis is composed of four core features: adversary, infrastructure, capability, and victim, and establishes the fundamental atomic element of any intrusion activity. The adversary is the person who stands behind the cyberattack. According to the Diamond Model, an adversary is an actor or organization responsible for utilizing a capability against the victim to achieve their intent. Adversary knowledge can generally be mysterious, and this core feature is likely to be empty for most events \u2013 at least at the time of discovery. It is difficult to identify an adversary during the first stages of a cyberattack. Utilizing data collected from an incident or breach, signatures, and other relevant information can help you determine who the adversary might be. Adversary Operator is the \u201chacker\u201d or person(s) conducting the intrusion activity. Adversary Customer is the entity that stands to benefit from the activity conducted in the intrusion. It may be the same person who stands behind the adversary operator, or it may be a separate person or group. The victim is the target of the adversary. A victim can be an organization, person, target email address, IP address, domain, etc. It's essential to understand the difference between the victim persona and the victim assets because they serve different analytic functions. Victim Personae are the people and organizations being targeted and whose assets are being attacked and exploited. These can be organization names, people\u2019s names, industries, job roles, interests, etc. Victim Assets are the attack surface and include the set of systems, networks, email addresses, hosts, IP addresses, social networking accounts, etc., to which the adversary will direct their capabilities. The capability is known as the skill, tools, and techniques used by the adversary in the event. The capability highlights the adversary\u2019s tactics, techniques, and procedures (TTPs). The capability can include all techniques used to attack the victims, from the less sophisticated methods, such as manual password guessing, to the most sophisticated techniques, like developing malware or a malicious tool. An Adversary Arsenal is a set of capabilities that belong to an adversary. The combined capacities of an adversary's capabilities make it the adversary's arsenal. Infrastructure is the physical or logical interconnections that the adversary uses to deliver a capability or maintain control of capabilities. For example, a command and control centre (C2) and the results from the victim (data exfiltration). The infrastructure can also be IP addresses, domain names, email addresses, or even a malicious USB device found in the street that is being plugged into a workstation. Type 1 Infrastructure is the infrastructure controlled or owned by the adversary. Type 2 Infrastructure is the infrastructure controlled by an intermediary. Sometimes the intermediary might or might not be aware of it. This is the infrastructure that a victim will see as the adversary. Type 2 Infrastructure has the purpose of obfuscating the source and attribution of the activity. Type 2 Infrastructure includes malware staging servers, malicious domain names, compromised email accounts, etc. Service Providers are organizations that provide services considered critical for the adversary availability of Type 1 and Type 2 Infrastructures, for example, Internet Service Providers, domain registrars, and webmail providers.","title":"DiamondModel"},{"location":"sec/Frameworks/DiamondModel/#the-diamond-model","text":"The Diamond Model of Intrusion Analysis is composed of four core features: adversary, infrastructure, capability, and victim, and establishes the fundamental atomic element of any intrusion activity. The adversary is the person who stands behind the cyberattack. According to the Diamond Model, an adversary is an actor or organization responsible for utilizing a capability against the victim to achieve their intent. Adversary knowledge can generally be mysterious, and this core feature is likely to be empty for most events \u2013 at least at the time of discovery. It is difficult to identify an adversary during the first stages of a cyberattack. Utilizing data collected from an incident or breach, signatures, and other relevant information can help you determine who the adversary might be. Adversary Operator is the \u201chacker\u201d or person(s) conducting the intrusion activity. Adversary Customer is the entity that stands to benefit from the activity conducted in the intrusion. It may be the same person who stands behind the adversary operator, or it may be a separate person or group. The victim is the target of the adversary. A victim can be an organization, person, target email address, IP address, domain, etc. It's essential to understand the difference between the victim persona and the victim assets because they serve different analytic functions. Victim Personae are the people and organizations being targeted and whose assets are being attacked and exploited. These can be organization names, people\u2019s names, industries, job roles, interests, etc. Victim Assets are the attack surface and include the set of systems, networks, email addresses, hosts, IP addresses, social networking accounts, etc., to which the adversary will direct their capabilities. The capability is known as the skill, tools, and techniques used by the adversary in the event. The capability highlights the adversary\u2019s tactics, techniques, and procedures (TTPs). The capability can include all techniques used to attack the victims, from the less sophisticated methods, such as manual password guessing, to the most sophisticated techniques, like developing malware or a malicious tool. An Adversary Arsenal is a set of capabilities that belong to an adversary. The combined capacities of an adversary's capabilities make it the adversary's arsenal. Infrastructure is the physical or logical interconnections that the adversary uses to deliver a capability or maintain control of capabilities. For example, a command and control centre (C2) and the results from the victim (data exfiltration). The infrastructure can also be IP addresses, domain names, email addresses, or even a malicious USB device found in the street that is being plugged into a workstation. Type 1 Infrastructure is the infrastructure controlled or owned by the adversary. Type 2 Infrastructure is the infrastructure controlled by an intermediary. Sometimes the intermediary might or might not be aware of it. This is the infrastructure that a victim will see as the adversary. Type 2 Infrastructure has the purpose of obfuscating the source and attribution of the activity. Type 2 Infrastructure includes malware staging servers, malicious domain names, compromised email accounts, etc. Service Providers are organizations that provide services considered critical for the adversary availability of Type 1 and Type 2 Infrastructures, for example, Internet Service Providers, domain registrars, and webmail providers.","title":"The Diamond Model"},{"location":"sec/Frameworks/NIST-CSF/","text":"NIST Cybersecurity Framework The NIST Cybersecurity Framework (NIST CSF) is a set of guidelines, best practices, and standards developed by the National Institute of Standards and Technology (NIST) to help organizations manage and improve their cybersecurity risk management processes. It was created in response to increasing cybersecurity threats and the need for a common language and approach to address cybersecurity challenges across different sectors and industries. The NIST CSF is designed to be adaptable and applicable to organizations of all sizes and industries, helping them to assess and manage cybersecurity risks in a structured and comprehensive manner. It provides a framework that assists organizations in identifying, protecting, detecting, responding to, and recovering from cybersecurity incidents. The framework is structured around three core components: Framework Core: This component consists of five functions that represent the key aspects of managing cybersecurity risk. These functions are: Identify: Understand and manage cybersecurity risks to systems, assets, data, and capabilities. Protect: Implement safeguards to protect against cyber threats. Detect: Develop and implement activities to identify cybersecurity events. Respond: Develop and implement plans to take action against detected cybersecurity incidents. Recover: Develop and implement plans for recovery and restoration after a cybersecurity incident. Framework Implementation Tiers: These tiers describe the maturity of an organization's cybersecurity program and its ability to manage and reduce cybersecurity risk. The tiers range from \"Partial\" (Tier 1) to \"Adaptive\" (Tier 4), with each tier indicating a higher level of integration and sophistication in the organization's cybersecurity practices. Framework Profiles: Profiles allow organizations to tailor the NIST CSF to their specific needs, priorities, and risk tolerance. A profile aligns an organization's cybersecurity activities with its business requirements, helping to establish a roadmap for cybersecurity improvement. The NIST CSF is a flexible and dynamic framework that organizations can use to improve their cybersecurity posture over time. It's important to note that the framework doesn't provide a one-size-fits-all solution but rather a structured approach to help organizations build and customize their cybersecurity strategies based on their unique risk landscape. Organizations can use the NIST CSF to: Identify and prioritize their cybersecurity risks. Develop and implement a cybersecurity strategy. Enhance communication about cybersecurity within the organization. Measure and monitor progress in managing cybersecurity risks. Establish a common language and understanding of cybersecurity concepts.","title":"NIST-CSF"},{"location":"sec/Frameworks/NIST-CSF/#nist-cybersecurity-framework","text":"The NIST Cybersecurity Framework (NIST CSF) is a set of guidelines, best practices, and standards developed by the National Institute of Standards and Technology (NIST) to help organizations manage and improve their cybersecurity risk management processes. It was created in response to increasing cybersecurity threats and the need for a common language and approach to address cybersecurity challenges across different sectors and industries. The NIST CSF is designed to be adaptable and applicable to organizations of all sizes and industries, helping them to assess and manage cybersecurity risks in a structured and comprehensive manner. It provides a framework that assists organizations in identifying, protecting, detecting, responding to, and recovering from cybersecurity incidents. The framework is structured around three core components: Framework Core: This component consists of five functions that represent the key aspects of managing cybersecurity risk. These functions are: Identify: Understand and manage cybersecurity risks to systems, assets, data, and capabilities. Protect: Implement safeguards to protect against cyber threats. Detect: Develop and implement activities to identify cybersecurity events. Respond: Develop and implement plans to take action against detected cybersecurity incidents. Recover: Develop and implement plans for recovery and restoration after a cybersecurity incident. Framework Implementation Tiers: These tiers describe the maturity of an organization's cybersecurity program and its ability to manage and reduce cybersecurity risk. The tiers range from \"Partial\" (Tier 1) to \"Adaptive\" (Tier 4), with each tier indicating a higher level of integration and sophistication in the organization's cybersecurity practices. Framework Profiles: Profiles allow organizations to tailor the NIST CSF to their specific needs, priorities, and risk tolerance. A profile aligns an organization's cybersecurity activities with its business requirements, helping to establish a roadmap for cybersecurity improvement. The NIST CSF is a flexible and dynamic framework that organizations can use to improve their cybersecurity posture over time. It's important to note that the framework doesn't provide a one-size-fits-all solution but rather a structured approach to help organizations build and customize their cybersecurity strategies based on their unique risk landscape. Organizations can use the NIST CSF to: Identify and prioritize their cybersecurity risks. Develop and implement a cybersecurity strategy. Enhance communication about cybersecurity within the organization. Measure and monitor progress in managing cybersecurity risks. Establish a common language and understanding of cybersecurity concepts.","title":"NIST Cybersecurity Framework"},{"location":"sec/Frameworks/PiramidOfPain/","text":"The Piramid of Pain The Pyramid of Pain is a conceptual model for the effective use of Cyber Threat Intelligence in threat detection operations, with a particular emphasis on increasing the adversaries' cost of operations. Hash values - SHA1, MD5, or other similar hashes that correspond to specific suspicious or malicious files. Security professionals usually use the hash values to gain insight into a specific malware sample, a malicious or a suspicious file, and as a way to uniquely identify and reference the malicious artifact. With so many variations and instances of known malware or ransomware, threat hunting using file hashes as the IOC (Indicators of Compromise) can become difficult. IP addresses - An IP address is used to identify any device connected to a network. From a defense standpoint, knowledge of the IP addresses an adversary uses can be valuable. A common defense tactic is to block, drop, or deny inbound requests from IP addresses on your parameter or external firewall. This tactic is often not bulletproof as it\u2019s trivial for an experienced adversary to recover simply by using a new public IP address. Domain names - A domain name itself, or sub domains. Domain Names can be a little more of a pain for the attacker to change as they would most likely need to purchase the domain, register it and modify DNS records. Unfortunately for defenders, many DNS providers have loose standards and provide APIs to make it even easier for the attacker to change the domain. Host artifacts - Host artifatcs are the traces or observables that attackers leave on the system, such as registry values, suspicious process execution, attack patterns or IOCs (Indicators of Compromise), files dropped by malicious applications, or anything exclusive to the current threat. The attacker would need to circle back at this detection level and change his attack tools and methodologies. This is very time-consuming for the attacker, and probably, he will need to spend more resources on his adversary tools. Network Artifacts - A network artifact can be a user-agent string, C2 information, or URI patterns followed by the HTTP POST requests. An attacker might use a User-Agent string that hasn\u2019t been observed in your environment before or seems out of the ordinary. The User-Agent is defined by RFC2616 as the request-header field that contains the information about the user agent originating the request. Tools - Software used by attackers to accomplish their mission. Attackers would use these utilities to create malicious macro documents (maldocs) for spearphishing attempts, a backdoor that can be used to establish C2 (Command and Control Infrastructure), any custom .EXE, and .DLL files, payloads, or password crackers. TTPs - Tactics, Techniques and Procedures (TTPs), which means all the steps taken by an adversary to achieve his goal, starting from reconnaissance or phishing attempts to persistence and data exfiltration. If you can detect and respond to TTPs quickly, you leave the adversaries almost no chance to fight back. At this point, the attacker would have no other choice but to go back, do more research and reconfigure their custom tools or to give up and find another target.","title":"PiramidOfPain"},{"location":"sec/Frameworks/PiramidOfPain/#the-piramid-of-pain","text":"The Pyramid of Pain is a conceptual model for the effective use of Cyber Threat Intelligence in threat detection operations, with a particular emphasis on increasing the adversaries' cost of operations. Hash values - SHA1, MD5, or other similar hashes that correspond to specific suspicious or malicious files. Security professionals usually use the hash values to gain insight into a specific malware sample, a malicious or a suspicious file, and as a way to uniquely identify and reference the malicious artifact. With so many variations and instances of known malware or ransomware, threat hunting using file hashes as the IOC (Indicators of Compromise) can become difficult. IP addresses - An IP address is used to identify any device connected to a network. From a defense standpoint, knowledge of the IP addresses an adversary uses can be valuable. A common defense tactic is to block, drop, or deny inbound requests from IP addresses on your parameter or external firewall. This tactic is often not bulletproof as it\u2019s trivial for an experienced adversary to recover simply by using a new public IP address. Domain names - A domain name itself, or sub domains. Domain Names can be a little more of a pain for the attacker to change as they would most likely need to purchase the domain, register it and modify DNS records. Unfortunately for defenders, many DNS providers have loose standards and provide APIs to make it even easier for the attacker to change the domain. Host artifacts - Host artifatcs are the traces or observables that attackers leave on the system, such as registry values, suspicious process execution, attack patterns or IOCs (Indicators of Compromise), files dropped by malicious applications, or anything exclusive to the current threat. The attacker would need to circle back at this detection level and change his attack tools and methodologies. This is very time-consuming for the attacker, and probably, he will need to spend more resources on his adversary tools. Network Artifacts - A network artifact can be a user-agent string, C2 information, or URI patterns followed by the HTTP POST requests. An attacker might use a User-Agent string that hasn\u2019t been observed in your environment before or seems out of the ordinary. The User-Agent is defined by RFC2616 as the request-header field that contains the information about the user agent originating the request. Tools - Software used by attackers to accomplish their mission. Attackers would use these utilities to create malicious macro documents (maldocs) for spearphishing attempts, a backdoor that can be used to establish C2 (Command and Control Infrastructure), any custom .EXE, and .DLL files, payloads, or password crackers. TTPs - Tactics, Techniques and Procedures (TTPs), which means all the steps taken by an adversary to achieve his goal, starting from reconnaissance or phishing attempts to persistence and data exfiltration. If you can detect and respond to TTPs quickly, you leave the adversaries almost no chance to fight back. At this point, the attacker would have no other choice but to go back, do more research and reconfigure their custom tools or to give up and find another target.","title":"The Piramid of Pain"},{"location":"sec/Frameworks/UnifiedKillChain/","text":"The Unified Kill Chain The Unified Kill Chain aims to complement with other cybersecurity kill chain frameworks such as Lockheed Martin\u2019s and MITRE\u2019s ATT&CK. The UKC identifies 18 phases to an attack, divided in 3 groups ( In , Through and Out ): everything from reconnaissance to data exfiltration and understanding an attacker's motive. Some large benefits of the UKC over traditional cybersecurity kill chain frameworks are the facts that it is extremely up-to-date and detailed.","title":"UnifiedKillChain"},{"location":"sec/Frameworks/UnifiedKillChain/#the-unified-kill-chain","text":"The Unified Kill Chain aims to complement with other cybersecurity kill chain frameworks such as Lockheed Martin\u2019s and MITRE\u2019s ATT&CK. The UKC identifies 18 phases to an attack, divided in 3 groups ( In , Through and Out ): everything from reconnaissance to data exfiltration and understanding an attacker's motive. Some large benefits of the UKC over traditional cybersecurity kill chain frameworks are the facts that it is extremely up-to-date and detailed.","title":"The Unified Kill Chain"},{"location":"sec/Protocols/DKIM/","text":"DomainKeys Identified Mail The DomainKeys Identified Mail (DKIM) is a cryptographic email authentication method that helps verify the authenticity of an email message. It allows the sender of an email to digitally sign the message using a private key, and the recipient can then verify the signature using a public key published in the sender's DNS records. This process ensures that the email hasn't been tampered with during transit and that it indeed came from the claimed sender domain. Here's how DKIM works with an example: Key Generation: The sending domain generates a pair of cryptographic keys: a private key and a corresponding public key. The private key remains confidential and is used to sign outgoing emails, while the public key is made available through DNS records. Signing Process: When the sending mail server wants to send an email, it generates a unique cryptographic hash of the email's contents (excluding certain headers). This hash is then encrypted using the private key, creating a digital signature. The signature is attached to the email as a DKIM-Signature header. DNS Record Update: The sender publishes the public key in their DNS records as a TXT record, associating it with the domain used to send emails. The public key is retrieved by the recipient's mail server when verifying the email's authenticity. Verification Process: When the recipient's mail server receives an email, it extracts the DKIM-Signature header and retrieves the public key from the sender's DNS records. The server then decrypts the signature using the public key, revealing the hash. The server also generates its own hash of the received email's contents (excluding certain headers). Comparison and Authentication: The recipient's server compares the two hashes \u2013 the one it generated and the one decrypted from the signature. If the hashes match, the email is considered authentic and hasn't been tampered with during transit. If they don't match, it suggests potential tampering, and the email might be treated as suspicious or even rejected. DKIM helps prevent email spoofing and ensures the integrity of emails, making it harder for malicious actors to forge the sender's identity or modify email content without detection. DNS record Example of a DKIM record for \"example.com\": default._domainkey.example.com. IN TXT \"v=DKIM1; k=rsa; p=MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC3Yh7GzR4sb9C9aVdktRaR0wI1 i4F5A1hx+I3h9SQcqP3s7wH6CfhZa/vU0xC/XL15Boek3ssW/JjBGOUeOfM3Q9uR q4aPLX7wdJlvA5Qx3Kf/EqZIyqCBjYirpvzGrf4bL+p3YbYYMPi0xMCwXvANRi6D ESCMzujE0bIG1d0W6wIDAQAB\" default._domainkey.example.com. : This is the selector for the DKIM key. The default selector is commonly used, and _domainkey.example.com is a subdomain used to host DKIM keys. IN TXT : This specifies the record type as a TXT record. \"v=DKIM1; k=rsa; p=MIGfMA0GCSq...\" : This is the DKIM record itself. It includes several key-value pairs: v=DKIM1 : Indicates the version of DKIM being used. k=rsa : Specifies the encryption algorithm (RSA in this case). p= : Contains the actual public key associated with DKIM. The long string is the actual public key value. When a recipient's mail server receives an email from \"example.com\", it will use the DKIM selector ( default._domainkey.example.com ) to look up the corresponding public key in the DNS TXT record. It will then use this public key to verify the authenticity of the DKIM signature in the email's header.","title":"DKIM"},{"location":"sec/Protocols/DKIM/#domainkeys-identified-mail","text":"The DomainKeys Identified Mail (DKIM) is a cryptographic email authentication method that helps verify the authenticity of an email message. It allows the sender of an email to digitally sign the message using a private key, and the recipient can then verify the signature using a public key published in the sender's DNS records. This process ensures that the email hasn't been tampered with during transit and that it indeed came from the claimed sender domain. Here's how DKIM works with an example: Key Generation: The sending domain generates a pair of cryptographic keys: a private key and a corresponding public key. The private key remains confidential and is used to sign outgoing emails, while the public key is made available through DNS records. Signing Process: When the sending mail server wants to send an email, it generates a unique cryptographic hash of the email's contents (excluding certain headers). This hash is then encrypted using the private key, creating a digital signature. The signature is attached to the email as a DKIM-Signature header. DNS Record Update: The sender publishes the public key in their DNS records as a TXT record, associating it with the domain used to send emails. The public key is retrieved by the recipient's mail server when verifying the email's authenticity. Verification Process: When the recipient's mail server receives an email, it extracts the DKIM-Signature header and retrieves the public key from the sender's DNS records. The server then decrypts the signature using the public key, revealing the hash. The server also generates its own hash of the received email's contents (excluding certain headers). Comparison and Authentication: The recipient's server compares the two hashes \u2013 the one it generated and the one decrypted from the signature. If the hashes match, the email is considered authentic and hasn't been tampered with during transit. If they don't match, it suggests potential tampering, and the email might be treated as suspicious or even rejected. DKIM helps prevent email spoofing and ensures the integrity of emails, making it harder for malicious actors to forge the sender's identity or modify email content without detection.","title":"DomainKeys Identified Mail"},{"location":"sec/Protocols/DKIM/#dns-record","text":"Example of a DKIM record for \"example.com\": default._domainkey.example.com. IN TXT \"v=DKIM1; k=rsa; p=MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC3Yh7GzR4sb9C9aVdktRaR0wI1 i4F5A1hx+I3h9SQcqP3s7wH6CfhZa/vU0xC/XL15Boek3ssW/JjBGOUeOfM3Q9uR q4aPLX7wdJlvA5Qx3Kf/EqZIyqCBjYirpvzGrf4bL+p3YbYYMPi0xMCwXvANRi6D ESCMzujE0bIG1d0W6wIDAQAB\" default._domainkey.example.com. : This is the selector for the DKIM key. The default selector is commonly used, and _domainkey.example.com is a subdomain used to host DKIM keys. IN TXT : This specifies the record type as a TXT record. \"v=DKIM1; k=rsa; p=MIGfMA0GCSq...\" : This is the DKIM record itself. It includes several key-value pairs: v=DKIM1 : Indicates the version of DKIM being used. k=rsa : Specifies the encryption algorithm (RSA in this case). p= : Contains the actual public key associated with DKIM. The long string is the actual public key value. When a recipient's mail server receives an email from \"example.com\", it will use the DKIM selector ( default._domainkey.example.com ) to look up the corresponding public key in the DNS TXT record. It will then use this public key to verify the authenticity of the DKIM signature in the email's header.","title":"DNS record"},{"location":"sec/Protocols/DMARC/","text":"Domain-based Message Authentication, Reporting, and Conformance DMARC stands for Domain-based Message Authentication, Reporting, and Conformance . It is an email authentication protocol designed to combat email phishing and spoofing by providing a way for domain owners to specify how email messages from their domain should be handled if they fail authentication checks. DMARC works by allowing domain owners to publish policies in their Domain Name System (DNS) records that instruct receiving mail servers on how to handle emails that claim to be from their domain. Here's how DMARC works: Authentication Mechanisms: DMARC builds upon two existing email authentication mechanisms: SPF (Sender Policy Framework) and DKIM (DomainKeys Identified Mail). SPF (Sender Policy Framework): SPF allows domain owners to specify which IP addresses and servers are authorized to send emails on behalf of their domain. When a receiving mail server gets an email claiming to be from a certain domain, it can check if the sending server's IP address is listed in that domain's SPF record. DKIM (DomainKeys Identified Mail): DKIM allows domain owners to sign outgoing emails with a digital signature. The receiving mail server can then verify this signature by checking the corresponding public key in the domain's DNS records. DMARC Policy: A domain owner publishes a DMARC policy in their DNS records, specifying how the receiving mail server should handle emails that fail SPF and DKIM checks. The policy can have three main actions: \"none,\" \"quarantine,\" and \"reject.\" None: The DMARC policy is set to \"none\" when the domain owner is in monitoring mode. It allows the domain owner to collect reports on failed authentication attempts without taking any action on the emails. Quarantine: The DMARC policy is set to \"quarantine\" when the domain owner wants the receiving mail server to treat emails that fail authentication as suspicious. These emails might be placed in the recipient's spam folder. Reject: The DMARC policy is set to \"reject\" when the domain owner wants the receiving mail server to outright reject emails that fail authentication. These emails are not delivered to the recipient's inbox. Reporting: DMARC also provides reporting mechanisms. Receiving mail servers can send aggregate and forensic reports back to the domain owner, detailing the authentication status of incoming emails claiming to be from their domain. These reports provide valuable insights into unauthorized use of the domain for phishing or spoofing attempts. DMARC helps domain owners protect their brand and recipients from phishing and spoofing attacks by specifying how receiving mail servers should handle emails that claim to originate from their domain. It builds upon SPF and DKIM authentication mechanisms and provides policies for action to be taken based on the authentication results. The reporting aspect of DMARC allows domain owners to monitor and improve their email authentication practices over time. DNS record Example of a DMARC record for the domain \"example.com\": _dmarc.example.com. IN TXT \"v=DMARC1; p=quarantine; rua=mailto:dmarc@example.com; ruf=mailto:dmarc@example.com; fo=1\" v=DMARC1 : This specifies the version of the DMARC protocol being used. p=quarantine : This sets the policy action to \"quarantine.\" It instructs receiving mail servers to treat emails that fail authentication as suspicious and potentially place them in the recipient's spam folder. rua=mailto:dmarc@example.com : This indicates where aggregate reports should be sent. In this example, aggregate reports will be sent to the email address \"dmarc@example.com.\" ruf=mailto:dmarc@example.com : This indicates where forensic (detailed) reports should be sent. Similar to aggregate reports, forensic reports will be sent to the email address \"dmarc@example.com.\" fo=1 : This specifies the format of the reports. The value \"1\" indicates that the reports should be generated in a human-readable format.","title":"DMARC"},{"location":"sec/Protocols/DMARC/#domain-based-message-authentication-reporting-and-conformance","text":"DMARC stands for Domain-based Message Authentication, Reporting, and Conformance . It is an email authentication protocol designed to combat email phishing and spoofing by providing a way for domain owners to specify how email messages from their domain should be handled if they fail authentication checks. DMARC works by allowing domain owners to publish policies in their Domain Name System (DNS) records that instruct receiving mail servers on how to handle emails that claim to be from their domain. Here's how DMARC works: Authentication Mechanisms: DMARC builds upon two existing email authentication mechanisms: SPF (Sender Policy Framework) and DKIM (DomainKeys Identified Mail). SPF (Sender Policy Framework): SPF allows domain owners to specify which IP addresses and servers are authorized to send emails on behalf of their domain. When a receiving mail server gets an email claiming to be from a certain domain, it can check if the sending server's IP address is listed in that domain's SPF record. DKIM (DomainKeys Identified Mail): DKIM allows domain owners to sign outgoing emails with a digital signature. The receiving mail server can then verify this signature by checking the corresponding public key in the domain's DNS records. DMARC Policy: A domain owner publishes a DMARC policy in their DNS records, specifying how the receiving mail server should handle emails that fail SPF and DKIM checks. The policy can have three main actions: \"none,\" \"quarantine,\" and \"reject.\" None: The DMARC policy is set to \"none\" when the domain owner is in monitoring mode. It allows the domain owner to collect reports on failed authentication attempts without taking any action on the emails. Quarantine: The DMARC policy is set to \"quarantine\" when the domain owner wants the receiving mail server to treat emails that fail authentication as suspicious. These emails might be placed in the recipient's spam folder. Reject: The DMARC policy is set to \"reject\" when the domain owner wants the receiving mail server to outright reject emails that fail authentication. These emails are not delivered to the recipient's inbox. Reporting: DMARC also provides reporting mechanisms. Receiving mail servers can send aggregate and forensic reports back to the domain owner, detailing the authentication status of incoming emails claiming to be from their domain. These reports provide valuable insights into unauthorized use of the domain for phishing or spoofing attempts. DMARC helps domain owners protect their brand and recipients from phishing and spoofing attacks by specifying how receiving mail servers should handle emails that claim to originate from their domain. It builds upon SPF and DKIM authentication mechanisms and provides policies for action to be taken based on the authentication results. The reporting aspect of DMARC allows domain owners to monitor and improve their email authentication practices over time.","title":"Domain-based Message Authentication, Reporting, and Conformance"},{"location":"sec/Protocols/DMARC/#dns-record","text":"Example of a DMARC record for the domain \"example.com\": _dmarc.example.com. IN TXT \"v=DMARC1; p=quarantine; rua=mailto:dmarc@example.com; ruf=mailto:dmarc@example.com; fo=1\" v=DMARC1 : This specifies the version of the DMARC protocol being used. p=quarantine : This sets the policy action to \"quarantine.\" It instructs receiving mail servers to treat emails that fail authentication as suspicious and potentially place them in the recipient's spam folder. rua=mailto:dmarc@example.com : This indicates where aggregate reports should be sent. In this example, aggregate reports will be sent to the email address \"dmarc@example.com.\" ruf=mailto:dmarc@example.com : This indicates where forensic (detailed) reports should be sent. Similar to aggregate reports, forensic reports will be sent to the email address \"dmarc@example.com.\" fo=1 : This specifies the format of the reports. The value \"1\" indicates that the reports should be generated in a human-readable format.","title":"DNS record"},{"location":"sec/Protocols/DNSSEC/","text":"Domain Name System Security Extensions DNSSEC , which stands for Domain Name System Security Extensions , is a technology used to enhance the security and authenticity of domain name system (DNS) data. DNS is responsible for translating human-readable domain names (like www.example.com) into IP addresses (like 192.0.2.1) that computers use to communicate over the internet. However, traditional DNS lacks inherent security measures, making it susceptible to various attacks like DNS spoofing, cache poisoning, and man-in-the-middle attacks. DNSSEC was developed to address these security vulnerabilities by adding digital signatures to DNS data. Here's how it works: Digital Signatures: DNSSEC uses cryptographic techniques to create digital signatures for DNS data. These signatures provide a way to verify the authenticity and integrity of DNS records. When a DNS record is signed, it includes a digital signature generated using a private key. Key Management: DNSSEC employs a hierarchical system of public keys and digital certificates. The top-level domain (TLD) operators, such as \".com\" or \".org,\" are responsible for signing their zone's data using their private key. This creates a chain of trust. The public key is then published in the DNS as a DNSKEY record. Validation: When a client, such as a web browser, queries a DNS resolver for a specific domain's IP address, the resolver follows the DNS hierarchy to obtain the necessary DNS records. If DNSSEC is enabled, the resolver also retrieves the corresponding DNSSEC-related records, like the DNSKEY and RRSIG (Resource Record Signature) records. Verification: The resolver uses the DNSKEY records to verify the digital signatures attached to the requested DNS records. It starts with the TLD's DNSKEY to verify the signature of the authoritative name server's DNSKEY. Then, it proceeds down the DNS hierarchy until it reaches the desired domain's authoritative name server. Chain of Trust: The chain of trust is established when each level's DNSKEY is used to verify the signature of the next level's DNSKEY. This process ensures that the data has not been tampered with and that it comes from a trusted source. Validation Results: If all signatures are valid and the chain of trust is unbroken, the resolver knows that the DNS data is genuine and has not been modified. It then provides the IP address to the client application, allowing it to establish the desired connection with the correct server. DNSSEC helps prevent attackers from injecting false DNS records into the system and redirecting users to malicious websites. However, while DNSSEC adds a layer of security to DNS, it's not a complete solution for all types of attacks. It does not encrypt the DNS data, and its effectiveness relies on proper implementation and management of cryptographic keys. DNSKEY and RRSIG records DNSKEY and RRSIG records of an example domain name \"example.com\" DNSKEY Record: The DNSKEY record contains the public key used for verifying the digital signatures. This record is signed by the zone's private key. example.com. IN DNSKEY 256 3 5 ( AQOeiiR0GOMYkDshWoSKz9Xz fwJr1AYtsmx3TGK3DzFYEZNam q2DdXK/xbJ87aBK8VyxDmYsM Y+gxw5J58EkMbNXMDOX4V9J1 9Xd58fLHJzHAOWUXp2AEUX7S nTCZG9xHiFfvQVWs8jN9/2Q== ) RRSIG Record: The RRSIG record contains the digital signature for a specific DNS record set. It's generated by the zone's private key and is used to verify the authenticity of the corresponding DNS record. www.example.com. IN RRSIG A 5 3 3600 ( 20230826000000 20230727000000 12345 example.com. A2R4TZuhv4Y2o7o6uG5RlGDS3 2T/+GzFdgQrWzU5e/3BfhbuK LJZbPBr6PfamXSjdGlmrNhXv 2U0yCjYHKFkOVLnJ7aZ8wekN Z9aGnZPzFfQnIsa0S7F4AEKr 1vWmcpe7dXd== ) In this example, the RRSIG record covers the \"A\" record for \"www.example.com\". The series of numbers after \"A2R4TZuhv4Y2o7o6uG5RlGDS3\" represent the timing information for the signature's validity period.","title":"DNSSEC"},{"location":"sec/Protocols/DNSSEC/#domain-name-system-security-extensions","text":"DNSSEC , which stands for Domain Name System Security Extensions , is a technology used to enhance the security and authenticity of domain name system (DNS) data. DNS is responsible for translating human-readable domain names (like www.example.com) into IP addresses (like 192.0.2.1) that computers use to communicate over the internet. However, traditional DNS lacks inherent security measures, making it susceptible to various attacks like DNS spoofing, cache poisoning, and man-in-the-middle attacks. DNSSEC was developed to address these security vulnerabilities by adding digital signatures to DNS data. Here's how it works: Digital Signatures: DNSSEC uses cryptographic techniques to create digital signatures for DNS data. These signatures provide a way to verify the authenticity and integrity of DNS records. When a DNS record is signed, it includes a digital signature generated using a private key. Key Management: DNSSEC employs a hierarchical system of public keys and digital certificates. The top-level domain (TLD) operators, such as \".com\" or \".org,\" are responsible for signing their zone's data using their private key. This creates a chain of trust. The public key is then published in the DNS as a DNSKEY record. Validation: When a client, such as a web browser, queries a DNS resolver for a specific domain's IP address, the resolver follows the DNS hierarchy to obtain the necessary DNS records. If DNSSEC is enabled, the resolver also retrieves the corresponding DNSSEC-related records, like the DNSKEY and RRSIG (Resource Record Signature) records. Verification: The resolver uses the DNSKEY records to verify the digital signatures attached to the requested DNS records. It starts with the TLD's DNSKEY to verify the signature of the authoritative name server's DNSKEY. Then, it proceeds down the DNS hierarchy until it reaches the desired domain's authoritative name server. Chain of Trust: The chain of trust is established when each level's DNSKEY is used to verify the signature of the next level's DNSKEY. This process ensures that the data has not been tampered with and that it comes from a trusted source. Validation Results: If all signatures are valid and the chain of trust is unbroken, the resolver knows that the DNS data is genuine and has not been modified. It then provides the IP address to the client application, allowing it to establish the desired connection with the correct server. DNSSEC helps prevent attackers from injecting false DNS records into the system and redirecting users to malicious websites. However, while DNSSEC adds a layer of security to DNS, it's not a complete solution for all types of attacks. It does not encrypt the DNS data, and its effectiveness relies on proper implementation and management of cryptographic keys.","title":"Domain Name System Security Extensions"},{"location":"sec/Protocols/DNSSEC/#dnskey-and-rrsig-records","text":"DNSKEY and RRSIG records of an example domain name \"example.com\" DNSKEY Record: The DNSKEY record contains the public key used for verifying the digital signatures. This record is signed by the zone's private key. example.com. IN DNSKEY 256 3 5 ( AQOeiiR0GOMYkDshWoSKz9Xz fwJr1AYtsmx3TGK3DzFYEZNam q2DdXK/xbJ87aBK8VyxDmYsM Y+gxw5J58EkMbNXMDOX4V9J1 9Xd58fLHJzHAOWUXp2AEUX7S nTCZG9xHiFfvQVWs8jN9/2Q== ) RRSIG Record: The RRSIG record contains the digital signature for a specific DNS record set. It's generated by the zone's private key and is used to verify the authenticity of the corresponding DNS record. www.example.com. IN RRSIG A 5 3 3600 ( 20230826000000 20230727000000 12345 example.com. A2R4TZuhv4Y2o7o6uG5RlGDS3 2T/+GzFdgQrWzU5e/3BfhbuK LJZbPBr6PfamXSjdGlmrNhXv 2U0yCjYHKFkOVLnJ7aZ8wekN Z9aGnZPzFfQnIsa0S7F4AEKr 1vWmcpe7dXd== ) In this example, the RRSIG record covers the \"A\" record for \"www.example.com\". The series of numbers after \"A2R4TZuhv4Y2o7o6uG5RlGDS3\" represent the timing information for the signature's validity period.","title":"DNSKEY and RRSIG records"},{"location":"sec/Protocols/IKE/","text":"Internet Key Exchange IKE stands for Internet Key Exchange , and it is a protocol used to establish a secure connection, typically in the context of Virtual Private Networks (VPNs) or other secure communication channels. IKE is a key component of the IPsec (Internet Protocol Security) suite of protocols that are used to ensure confidentiality, integrity, and authenticity of data transmitted over a network. The primary purpose of IKE is to negotiate the cryptographic keys and parameters needed for the encryption and authentication of data. It is a critical part of establishing a secure communication channel between two parties, such as two network devices or a user's device and a VPN gateway. Here's a high-level overview of how IKE works: Initiation - The process begins with one party (referred to as the initiator) sending an IKE negotiation request to the other party (the responder). Security Association (SA) Proposal - The initiator proposes a set of security parameters, including encryption algorithms, authentication methods, and other cryptographic attributes. These parameters are defined in an SA proposal. Responder's Selection - The responder reviews the SA proposal and selects the appropriate security parameters based on its own configuration and policies. Key Exchange - The initiator and responder engage in a key exchange process to generate a shared secret key without directly transmitting it over the network. This is often done using Diffie-Hellman key exchange, which allows both parties to derive a common secret key even if an eavesdropper intercepts the communication. Authentication - Both parties authenticate each other using digital certificates, pre-shared keys, or other methods, depending on the chosen authentication mechanism. Establishment of Security Associations - With the shared secret key and authentication established, both parties create a Security Association (SA) that contains the negotiated parameters. An SA is a logical connection that defines the security attributes for the communication session. Data Exchange - Once the security association is established, data packets can be encrypted and decrypted using the agreed-upon encryption algorithms and keys. This ensures that the data transmitted between the two parties remains confidential and protected from unauthorized access. Periodic Rekeying - Security associations have a limited lifetime for security reasons. IKE also supports the automatic negotiation of new keys before the current ones expire. This process is known as rekeying and helps maintain the security of the communication channel. It's important to note that IKE can operate in different modes, such as main mode and aggressive mode, each with its own characteristics and trade-offs in terms of security and efficiency.","title":"IKE"},{"location":"sec/Protocols/IKE/#internet-key-exchange","text":"IKE stands for Internet Key Exchange , and it is a protocol used to establish a secure connection, typically in the context of Virtual Private Networks (VPNs) or other secure communication channels. IKE is a key component of the IPsec (Internet Protocol Security) suite of protocols that are used to ensure confidentiality, integrity, and authenticity of data transmitted over a network. The primary purpose of IKE is to negotiate the cryptographic keys and parameters needed for the encryption and authentication of data. It is a critical part of establishing a secure communication channel between two parties, such as two network devices or a user's device and a VPN gateway. Here's a high-level overview of how IKE works: Initiation - The process begins with one party (referred to as the initiator) sending an IKE negotiation request to the other party (the responder). Security Association (SA) Proposal - The initiator proposes a set of security parameters, including encryption algorithms, authentication methods, and other cryptographic attributes. These parameters are defined in an SA proposal. Responder's Selection - The responder reviews the SA proposal and selects the appropriate security parameters based on its own configuration and policies. Key Exchange - The initiator and responder engage in a key exchange process to generate a shared secret key without directly transmitting it over the network. This is often done using Diffie-Hellman key exchange, which allows both parties to derive a common secret key even if an eavesdropper intercepts the communication. Authentication - Both parties authenticate each other using digital certificates, pre-shared keys, or other methods, depending on the chosen authentication mechanism. Establishment of Security Associations - With the shared secret key and authentication established, both parties create a Security Association (SA) that contains the negotiated parameters. An SA is a logical connection that defines the security attributes for the communication session. Data Exchange - Once the security association is established, data packets can be encrypted and decrypted using the agreed-upon encryption algorithms and keys. This ensures that the data transmitted between the two parties remains confidential and protected from unauthorized access. Periodic Rekeying - Security associations have a limited lifetime for security reasons. IKE also supports the automatic negotiation of new keys before the current ones expire. This process is known as rekeying and helps maintain the security of the communication channel. It's important to note that IKE can operate in different modes, such as main mode and aggressive mode, each with its own characteristics and trade-offs in terms of security and efficiency.","title":"Internet Key Exchange"},{"location":"sec/Protocols/IPsec/","text":"Internet Protocol Security IPSec , short for Internet Protocol Security , is a suite of protocols and cryptographic techniques used to secure and protect communication over IP networks. It provides a framework for ensuring the confidentiality, integrity, and authenticity of data transmitted between devices in a network, typically over the Internet. IPSec operates at the network layer (Layer 3) of the OSI model and can be used to establish Virtual Private Networks (VPNs) or to secure individual network connections. It offers two main modes of operation: Transport Mode and Tunnel Mode . Here's how IPSec works: Authentication and Key Exchange : Before secure communication can begin, the two devices (or endpoints) that want to communicate need to establish a secure channel and exchange cryptographic keys. This is usually done using protocols like the Internet Key Exchange (IKE) protocol. IKE negotiates the encryption algorithm, authentication method, and other security parameters to be used during the communication. Encapsulation and Encryption : Once the keys and security parameters are established, the data to be transmitted is encapsulated within an IPSec packet. This encapsulation involves adding an IPSec header to the original IP packet. The IPSec header contains information needed for the secure transmission, such as the security parameters, sequence numbers, and other metadata. Encryption and Authentication : The encapsulated data is encrypted to ensure its confidentiality. Encryption algorithms like AES (Advanced Encryption Standard) are commonly used for this purpose. Additionally, the data is authenticated using HMAC (Hash-based Message Authentication Code) algorithms to detect any tampering or unauthorized changes during transmission. Transmission and Decryption : The IPSec-protected packet is then transmitted over the network. Routers and firewalls along the route can apply IPSec policies to enforce security requirements. When the packet reaches the receiving endpoint, it's decrypted using the appropriate cryptographic keys and algorithms. The authenticity of the packet is verified through the authentication information added in the IPSec header. Decapsulation : Once the packet is decrypted and authenticated, the original IP packet is extracted from the IPSec packet. This process involves removing the IPSec header and any additional encapsulation layers. By implementing these steps, IPSec ensures that data integrity is maintained, data confidentiality is preserved, and the authenticity of the communication partners is verified. It's worth noting that while IPSec provides a strong level of security, proper configuration and management are crucial to ensure its effectiveness. Transport and Tunnel modes IPSec offers two main modes of operation: Transport Mode and Tunnel Mode . These modes determine how IPSec is applied to the communication between two devices (or endpoints) and how the original IP packets are protected and secured. Transport Mode : In Transport Mode, IPSec secures the payload of the original IP packet while leaving the original IP header intact. This mode is typically used when the communication is between two endpoints, and the devices want to secure the data being transmitted without changing the original source and destination IP addresses. Here's how Transport Mode works: The original IP packet's payload is encrypted and authenticated. An additional IPSec header is added to the encrypted payload, containing information related to IPSec security associations. The encrypted packet is then sent over the network with the original IP header still visible. Transport Mode is commonly used for end-to-end communication, such as securing VoIP calls or secure communications within a private network. Tunnel Mode : In Tunnel Mode, IPSec encapsulates the entire original IP packet within a new IPSec-protected packet. This new packet, often referred to as the \"tunnel,\" has its own IP header, which means the original source and destination IP addresses are now the endpoints of the tunnel. This mode is used when communication needs to be secured between two networks or when there is a need to hide the original source and destination IP addresses. Here's how Tunnel Mode works: The original IP packet (including its IP header and payload) is encrypted and authenticated. An IPSec header is added to the encrypted packet, containing information about the IPSec security associations and the new tunnel IP header. A new outer IP header is added to the packet, specifying the source and destination of the tunnel endpoints. Tunnel Mode is often used for creating Virtual Private Networks (VPNs), connecting remote offices or individual devices to a central network, and securing communication between different networks over the Internet. In summary, Transport Mode encrypts and secures the data within the original IP packet, while Tunnel Mode encapsulates the entire original IP packet within a new IPSec-protected packet. The choice between these modes depends on the specific security requirements and the nature of the communication: whether it's end-to-end between devices or between networks. IPsec packets Certainly! Let's consider an example scenario where two devices, Device A and Device B, are communicating using IPSec in both Transport Mode and Tunnel Mode. 1. IPSec Transport Mode: In Transport Mode, only the payload of the original IP packet is encrypted and authenticated. The original IP header remains intact. Original IP Header +-------------------------------+ | Version | IHL | DSCP | ECN | +-------------------------------+ | Total Length | Identification | +-------------------------------+ | Flags | Fragment Offset | +-------------------------------+ | TTL | Protocol | Header | | | | Checksum | +-------------------------------+ | Source IP Address | +-------------------------------+ | Destination IP Address | +-------------------------------+ | IPSec Header | | +---------------------------+ | | | Next Header | Payload | | | | | Length | | | +---------------------------+ | | | Security Parameters | | | | +-----------------------+ | | | | | ... (SPI, Seq #, | | | | | | Encryption, Auth, | | | | | | Key Exchange Params)| | | | | +-----------------------+ | | | +---------------------------+ | +-------------------------------+ | Encrypted Payload | | +---------------------------+ | | | Data | | | +---------------------------+ | +-------------------------------+ The \"Original IP Header\" includes various fields such as the version, header length, DSCP (Differentiated Services Code Point), ECN (Explicit Congestion Notification), identification, flags, fragment offset, TTL (Time to Live), protocol, header checksum, source IP address, and destination IP address. This is the standard IP header of the original packet. The \"IPSec Header\" follows the original IP header. It includes fields like \"Next Header\" (indicating the type of payload following the IPSec header) and \"Payload Length\" (length of the IPSec payload, excluding the header). Within the \"IPSec Header,\" there are \"Security Parameters\" which encompass information such as Security Parameter Index (SPI), sequence number, encryption algorithm, authentication algorithm, and other key exchange parameters. These parameters are necessary for securing and authenticating the communication. The \"Encrypted Payload\" contains the actual data of the original packet. This data has been encrypted to ensure confidentiality and integrity during transmission. 2. IPSec Tunnel Mode: In Tunnel Mode, the entire original IP packet, including its header and payload, is encapsulated within a new IPSec-protected packet with its own IP header. Original IP Header +-------------------------------+ | Version | IHL | DSCP | ECN | +-------------------------------+ | Total Length | Identification | +-------------------------------+ | Flags | Fragment Offset | +-------------------------------+ | TTL | Protocol | Header | | | | Checksum | +-------------------------------+ | Source IP Address | +-------------------------------+ | Destination IP Address | +-------------------------------+ | New IP Header (Tunnel) | | +---------------------------+ | | | Version | IHL | DSCP | ECN | | +---------------------------+ | | | Total Length|Identification | | +---------------------------+ | | | Flags | Fragment Offset | | | +---------------------------+ | | | TTL | Protocol | Header | | | | | Checksum | | +---------------------------+ | | | Source IP (Tunnel Source) | | | +---------------------------+ | | | Destination IP (Tunnel | | | | Destination) | | | +---------------------------+ | | IPSec Header | | +---------------------------+ | | | Next Header | Payload | | | | | Length | | | +---------------------------+ | | | Security Parameters | | | | +-----------------------+ | | | | | ... (SPI, Seq #, | | | | | | Encryption, Auth, | | | | | | Key Exchange Params)| | | | | +-----------------------+ | | | +---------------------------+ | +-------------------------------+ | Encrypted Payload | | +---------------------------+ | | | Data | | | +---------------------------+ | +-------------------------------+ The \"Original IP Header\" remains the same as in the Transport Mode representation, including all the standard fields of an IP header. Following the \"Original IP Header,\" there's a \"New IP Header (Tunnel)\" that encapsulates the entire original packet. This new IP header serves as the outer header for the tunnel. It includes fields like version, IHL, DSCP, ECN, total length, identification, flags, fragment offset, TTL, protocol, header checksum, source IP (the tunnel source), and destination IP (the tunnel destination). After the \"New IP Header (Tunnel),\" there's the \"IPSec Header,\" which contains similar fields already mentioned before: \"Next Header,\" \"Payload Length,\" and \"Security Parameters.\" The \"Encrypted Payload\" contains the actual data of the original packet, encrypted for confidentiality.","title":"IPsec"},{"location":"sec/Protocols/IPsec/#internet-protocol-security","text":"IPSec , short for Internet Protocol Security , is a suite of protocols and cryptographic techniques used to secure and protect communication over IP networks. It provides a framework for ensuring the confidentiality, integrity, and authenticity of data transmitted between devices in a network, typically over the Internet. IPSec operates at the network layer (Layer 3) of the OSI model and can be used to establish Virtual Private Networks (VPNs) or to secure individual network connections. It offers two main modes of operation: Transport Mode and Tunnel Mode . Here's how IPSec works: Authentication and Key Exchange : Before secure communication can begin, the two devices (or endpoints) that want to communicate need to establish a secure channel and exchange cryptographic keys. This is usually done using protocols like the Internet Key Exchange (IKE) protocol. IKE negotiates the encryption algorithm, authentication method, and other security parameters to be used during the communication. Encapsulation and Encryption : Once the keys and security parameters are established, the data to be transmitted is encapsulated within an IPSec packet. This encapsulation involves adding an IPSec header to the original IP packet. The IPSec header contains information needed for the secure transmission, such as the security parameters, sequence numbers, and other metadata. Encryption and Authentication : The encapsulated data is encrypted to ensure its confidentiality. Encryption algorithms like AES (Advanced Encryption Standard) are commonly used for this purpose. Additionally, the data is authenticated using HMAC (Hash-based Message Authentication Code) algorithms to detect any tampering or unauthorized changes during transmission. Transmission and Decryption : The IPSec-protected packet is then transmitted over the network. Routers and firewalls along the route can apply IPSec policies to enforce security requirements. When the packet reaches the receiving endpoint, it's decrypted using the appropriate cryptographic keys and algorithms. The authenticity of the packet is verified through the authentication information added in the IPSec header. Decapsulation : Once the packet is decrypted and authenticated, the original IP packet is extracted from the IPSec packet. This process involves removing the IPSec header and any additional encapsulation layers. By implementing these steps, IPSec ensures that data integrity is maintained, data confidentiality is preserved, and the authenticity of the communication partners is verified. It's worth noting that while IPSec provides a strong level of security, proper configuration and management are crucial to ensure its effectiveness.","title":"Internet Protocol Security"},{"location":"sec/Protocols/IPsec/#transport-and-tunnel-modes","text":"IPSec offers two main modes of operation: Transport Mode and Tunnel Mode . These modes determine how IPSec is applied to the communication between two devices (or endpoints) and how the original IP packets are protected and secured. Transport Mode : In Transport Mode, IPSec secures the payload of the original IP packet while leaving the original IP header intact. This mode is typically used when the communication is between two endpoints, and the devices want to secure the data being transmitted without changing the original source and destination IP addresses. Here's how Transport Mode works: The original IP packet's payload is encrypted and authenticated. An additional IPSec header is added to the encrypted payload, containing information related to IPSec security associations. The encrypted packet is then sent over the network with the original IP header still visible. Transport Mode is commonly used for end-to-end communication, such as securing VoIP calls or secure communications within a private network. Tunnel Mode : In Tunnel Mode, IPSec encapsulates the entire original IP packet within a new IPSec-protected packet. This new packet, often referred to as the \"tunnel,\" has its own IP header, which means the original source and destination IP addresses are now the endpoints of the tunnel. This mode is used when communication needs to be secured between two networks or when there is a need to hide the original source and destination IP addresses. Here's how Tunnel Mode works: The original IP packet (including its IP header and payload) is encrypted and authenticated. An IPSec header is added to the encrypted packet, containing information about the IPSec security associations and the new tunnel IP header. A new outer IP header is added to the packet, specifying the source and destination of the tunnel endpoints. Tunnel Mode is often used for creating Virtual Private Networks (VPNs), connecting remote offices or individual devices to a central network, and securing communication between different networks over the Internet. In summary, Transport Mode encrypts and secures the data within the original IP packet, while Tunnel Mode encapsulates the entire original IP packet within a new IPSec-protected packet. The choice between these modes depends on the specific security requirements and the nature of the communication: whether it's end-to-end between devices or between networks.","title":"Transport and Tunnel modes"},{"location":"sec/Protocols/IPsec/#ipsec-packets","text":"Certainly! Let's consider an example scenario where two devices, Device A and Device B, are communicating using IPSec in both Transport Mode and Tunnel Mode. 1. IPSec Transport Mode: In Transport Mode, only the payload of the original IP packet is encrypted and authenticated. The original IP header remains intact. Original IP Header +-------------------------------+ | Version | IHL | DSCP | ECN | +-------------------------------+ | Total Length | Identification | +-------------------------------+ | Flags | Fragment Offset | +-------------------------------+ | TTL | Protocol | Header | | | | Checksum | +-------------------------------+ | Source IP Address | +-------------------------------+ | Destination IP Address | +-------------------------------+ | IPSec Header | | +---------------------------+ | | | Next Header | Payload | | | | | Length | | | +---------------------------+ | | | Security Parameters | | | | +-----------------------+ | | | | | ... (SPI, Seq #, | | | | | | Encryption, Auth, | | | | | | Key Exchange Params)| | | | | +-----------------------+ | | | +---------------------------+ | +-------------------------------+ | Encrypted Payload | | +---------------------------+ | | | Data | | | +---------------------------+ | +-------------------------------+ The \"Original IP Header\" includes various fields such as the version, header length, DSCP (Differentiated Services Code Point), ECN (Explicit Congestion Notification), identification, flags, fragment offset, TTL (Time to Live), protocol, header checksum, source IP address, and destination IP address. This is the standard IP header of the original packet. The \"IPSec Header\" follows the original IP header. It includes fields like \"Next Header\" (indicating the type of payload following the IPSec header) and \"Payload Length\" (length of the IPSec payload, excluding the header). Within the \"IPSec Header,\" there are \"Security Parameters\" which encompass information such as Security Parameter Index (SPI), sequence number, encryption algorithm, authentication algorithm, and other key exchange parameters. These parameters are necessary for securing and authenticating the communication. The \"Encrypted Payload\" contains the actual data of the original packet. This data has been encrypted to ensure confidentiality and integrity during transmission. 2. IPSec Tunnel Mode: In Tunnel Mode, the entire original IP packet, including its header and payload, is encapsulated within a new IPSec-protected packet with its own IP header. Original IP Header +-------------------------------+ | Version | IHL | DSCP | ECN | +-------------------------------+ | Total Length | Identification | +-------------------------------+ | Flags | Fragment Offset | +-------------------------------+ | TTL | Protocol | Header | | | | Checksum | +-------------------------------+ | Source IP Address | +-------------------------------+ | Destination IP Address | +-------------------------------+ | New IP Header (Tunnel) | | +---------------------------+ | | | Version | IHL | DSCP | ECN | | +---------------------------+ | | | Total Length|Identification | | +---------------------------+ | | | Flags | Fragment Offset | | | +---------------------------+ | | | TTL | Protocol | Header | | | | | Checksum | | +---------------------------+ | | | Source IP (Tunnel Source) | | | +---------------------------+ | | | Destination IP (Tunnel | | | | Destination) | | | +---------------------------+ | | IPSec Header | | +---------------------------+ | | | Next Header | Payload | | | | | Length | | | +---------------------------+ | | | Security Parameters | | | | +-----------------------+ | | | | | ... (SPI, Seq #, | | | | | | Encryption, Auth, | | | | | | Key Exchange Params)| | | | | +-----------------------+ | | | +---------------------------+ | +-------------------------------+ | Encrypted Payload | | +---------------------------+ | | | Data | | | +---------------------------+ | +-------------------------------+ The \"Original IP Header\" remains the same as in the Transport Mode representation, including all the standard fields of an IP header. Following the \"Original IP Header,\" there's a \"New IP Header (Tunnel)\" that encapsulates the entire original packet. This new IP header serves as the outer header for the tunnel. It includes fields like version, IHL, DSCP, ECN, total length, identification, flags, fragment offset, TTL, protocol, header checksum, source IP (the tunnel source), and destination IP (the tunnel destination). After the \"New IP Header (Tunnel),\" there's the \"IPSec Header,\" which contains similar fields already mentioned before: \"Next Header,\" \"Payload Length,\" and \"Security Parameters.\" The \"Encrypted Payload\" contains the actual data of the original packet, encrypted for confidentiality.","title":"IPsec packets"},{"location":"sec/Protocols/MTA-STS/","text":"Mail Transfer Agent and Strict Transport Security MTA-STS stands for Mail Transfer Agent Strict Transport Security . It is a security protocol designed to enhance the security of email communication by enforcing encryption and ensuring secure communication between email servers. MTA-STS helps prevent certain types of attacks, such as man-in-the-middle attacks, which can compromise the confidentiality and integrity of email messages. Here's how MTA-STS works: Enabling MTA-STS: A domain owner sets up MTA-STS for their domain by creating a policy file and hosting it on a specified HTTPS server. This policy file contains information about the domain's MTA-STS policy, including the MX (Mail Exchange) hosts that support TLS (Transport Layer Security) encryption. DNS Records: The domain owner also adds DNS records for their domain to indicate the existence of an MTA-STS policy and the location of the policy file. These DNS records are of type TXT and _mta-sts . Policy Discovery: When an email server wants to send an email to a recipient at a domain with an MTA-STS policy, it first performs a DNS lookup for the _mta-sts record of the recipient's domain. This record contains the URL of the policy file. Policy Fetching: The email server then retrieves the MTA-STS policy file using the provided URL over HTTPS. The policy file specifies which MX hosts are expected to support encrypted connections (TLS) for sending emails. Policy Enforcement: The sending email server establishes an encrypted connection (TLS) with the recipient's email server, using the MX hosts specified in the policy file. If the recipient's server does not support encrypted connections, the sending server should reject the email transmission or take appropriate action as per the policy. Caching and Timing: MTA-STS policies have a \"max-age\" directive that specifies how long the policy can be cached. This allows email servers to cache the policy and avoid repeated DNS and HTTPS requests for a certain period. The domain owner can also include a \"preload\" directive to signal to major email providers that their policy should be preloaded into email servers, providing more immediate protection. In summary, MTA-STS is a mechanism that helps ensure that email communication between servers is encrypted using TLS, thereby enhancing the security and privacy of email messages. It is part of ongoing efforts to improve the security of email communication and mitigate potential vulnerabilities and attacks. Policy and DNS record Example of an MTA-STS policy file and the corresponding DNS records for the domain \"example.com\": MTA-STS Policy File (example.com.mta-sts.txt): version: STSv1 mode: enforce max_age: 86400 # 1 day in seconds mx: mx1.example.com mx: mx2.example.com In this example policy file: - version : Specifies the version of the MTA-STS policy. - mode : Sets the policy mode. \"enforce\" means that the policy should be enforced, requiring encrypted connections. - max_age : Specifies how long the policy can be cached. Here, it's set to 1 day (86400 seconds). - mx : Lists the MX hosts that should support TLS for sending emails. DNS Records: Add the following DNS records for the \"example.com\" domain: _mta-sts.example.com TXT record: v=STSv1; id=20230101T123456Z; This record indicates the existence of an MTA-STS policy and includes the current date and time in UTC. _smtp._tls.example.com MX record: 10 mx1.example.com 20 mx2.example.com This record points to the MX hosts that are specified in the MTA-STS policy file. The \"10\" and \"20\" are the priority values, and \"mx1.example.com\" and \"mx2.example.com\" are the domain's mail exchange servers.","title":"MTA-STS"},{"location":"sec/Protocols/MTA-STS/#mail-transfer-agent-and-strict-transport-security","text":"MTA-STS stands for Mail Transfer Agent Strict Transport Security . It is a security protocol designed to enhance the security of email communication by enforcing encryption and ensuring secure communication between email servers. MTA-STS helps prevent certain types of attacks, such as man-in-the-middle attacks, which can compromise the confidentiality and integrity of email messages. Here's how MTA-STS works: Enabling MTA-STS: A domain owner sets up MTA-STS for their domain by creating a policy file and hosting it on a specified HTTPS server. This policy file contains information about the domain's MTA-STS policy, including the MX (Mail Exchange) hosts that support TLS (Transport Layer Security) encryption. DNS Records: The domain owner also adds DNS records for their domain to indicate the existence of an MTA-STS policy and the location of the policy file. These DNS records are of type TXT and _mta-sts . Policy Discovery: When an email server wants to send an email to a recipient at a domain with an MTA-STS policy, it first performs a DNS lookup for the _mta-sts record of the recipient's domain. This record contains the URL of the policy file. Policy Fetching: The email server then retrieves the MTA-STS policy file using the provided URL over HTTPS. The policy file specifies which MX hosts are expected to support encrypted connections (TLS) for sending emails. Policy Enforcement: The sending email server establishes an encrypted connection (TLS) with the recipient's email server, using the MX hosts specified in the policy file. If the recipient's server does not support encrypted connections, the sending server should reject the email transmission or take appropriate action as per the policy. Caching and Timing: MTA-STS policies have a \"max-age\" directive that specifies how long the policy can be cached. This allows email servers to cache the policy and avoid repeated DNS and HTTPS requests for a certain period. The domain owner can also include a \"preload\" directive to signal to major email providers that their policy should be preloaded into email servers, providing more immediate protection. In summary, MTA-STS is a mechanism that helps ensure that email communication between servers is encrypted using TLS, thereby enhancing the security and privacy of email messages. It is part of ongoing efforts to improve the security of email communication and mitigate potential vulnerabilities and attacks.","title":"Mail Transfer Agent and Strict Transport Security"},{"location":"sec/Protocols/MTA-STS/#policy-and-dns-record","text":"Example of an MTA-STS policy file and the corresponding DNS records for the domain \"example.com\": MTA-STS Policy File (example.com.mta-sts.txt): version: STSv1 mode: enforce max_age: 86400 # 1 day in seconds mx: mx1.example.com mx: mx2.example.com In this example policy file: - version : Specifies the version of the MTA-STS policy. - mode : Sets the policy mode. \"enforce\" means that the policy should be enforced, requiring encrypted connections. - max_age : Specifies how long the policy can be cached. Here, it's set to 1 day (86400 seconds). - mx : Lists the MX hosts that should support TLS for sending emails. DNS Records: Add the following DNS records for the \"example.com\" domain: _mta-sts.example.com TXT record: v=STSv1; id=20230101T123456Z; This record indicates the existence of an MTA-STS policy and includes the current date and time in UTC. _smtp._tls.example.com MX record: 10 mx1.example.com 20 mx2.example.com This record points to the MX hosts that are specified in the MTA-STS policy file. The \"10\" and \"20\" are the priority values, and \"mx1.example.com\" and \"mx2.example.com\" are the domain's mail exchange servers.","title":"Policy and DNS record"},{"location":"sec/Protocols/SPF/","text":"Sender Policy Framework The Sender Policy Framework (SPF) is an email authentication method designed to prevent email spoofing and unauthorized use of a domain's name in email headers. SPF works by allowing domain owners to specify which IP addresses or ranges are authorized to send emails on behalf of their domain. An SPF record is a DNS TXT record containing a list of the IP addresses that are allowed to send email on behalf of your domain. These authorized sources are defined in the record using SPF mechanisms: IP Address Mechanism ( ip4 and ip6 ): This mechanism specifies a specific IP address or range of IPv4 ( ip4 ) or IPv6 ( ip6 ) addresses that are authorized to send emails for the domain. For example: v=spf1 ip4:192.168.1.1/24 -all allows the IP range 192.168.1.1 to 192.168.1.255 to send emails. v=spf1 ip6:2001:db8::/32 -all allows the IPv6 range 2001:db8:: to 2001:db8:ffff:ffff:ffff:ffff:ffff:ffff to send emails. Domain Mechanism ( a and mx ): These mechanisms refer to the IP addresses of the domain's A records ( a ) or MX records ( mx ). They allow the IP addresses associated with the domain's DNS records to send emails. For example: v=spf1 a -all authorizes the IP address of the domain's A record. v=spf1 mx -all authorizes the IP addresses of the domain's MX records. Include Mechanism ( include ): This mechanism allows you to include SPF records from another domain within your own SPF record. It's useful when you're using a third-party service to send emails on behalf of your domain. For example: v=spf1 include:_spf.example.com -all includes the SPF record of _spf.example.com in your SPF policy. All Mechanism ( all ): This mechanism defines the default action for emails that don't match any of the specified mechanisms. There are three possible outcomes: -all : Deny all emails that do not match any mechanism (recommended for strict policies). ~all : Soft fail, where the email is less likely to be accepted but not outright rejected. ?all : Neutral, indicating that the policy is neither positive nor negative. Redirect Mechanism ( redirect ): This mechanism is used to specify a domain that will provide the actual SPF record for authorization. The receiving server will look up the provided domain for the SPF record and use it to evaluate the email. For example: v=spf1 redirect=spf.example.com directs to the SPF record of spf.example.com . Explanation Mechanism ( exp ): This mechanism is used to provide a human-readable explanation for the SPF policy. It's not widely supported and mainly serves as a comment. For example: v=spf1 exp=Explanation for this SPF policy -all . SPF mechanisms are combined to create a comprehensive SPF record that specifies which sources are authorized to send emails on behalf of a domain. It's important to carefully design your SPF policy to ensure legitimate emails are not rejected and unauthorized emails are properly blocked.","title":"SPF"},{"location":"sec/Protocols/SPF/#sender-policy-framework","text":"The Sender Policy Framework (SPF) is an email authentication method designed to prevent email spoofing and unauthorized use of a domain's name in email headers. SPF works by allowing domain owners to specify which IP addresses or ranges are authorized to send emails on behalf of their domain. An SPF record is a DNS TXT record containing a list of the IP addresses that are allowed to send email on behalf of your domain. These authorized sources are defined in the record using SPF mechanisms: IP Address Mechanism ( ip4 and ip6 ): This mechanism specifies a specific IP address or range of IPv4 ( ip4 ) or IPv6 ( ip6 ) addresses that are authorized to send emails for the domain. For example: v=spf1 ip4:192.168.1.1/24 -all allows the IP range 192.168.1.1 to 192.168.1.255 to send emails. v=spf1 ip6:2001:db8::/32 -all allows the IPv6 range 2001:db8:: to 2001:db8:ffff:ffff:ffff:ffff:ffff:ffff to send emails. Domain Mechanism ( a and mx ): These mechanisms refer to the IP addresses of the domain's A records ( a ) or MX records ( mx ). They allow the IP addresses associated with the domain's DNS records to send emails. For example: v=spf1 a -all authorizes the IP address of the domain's A record. v=spf1 mx -all authorizes the IP addresses of the domain's MX records. Include Mechanism ( include ): This mechanism allows you to include SPF records from another domain within your own SPF record. It's useful when you're using a third-party service to send emails on behalf of your domain. For example: v=spf1 include:_spf.example.com -all includes the SPF record of _spf.example.com in your SPF policy. All Mechanism ( all ): This mechanism defines the default action for emails that don't match any of the specified mechanisms. There are three possible outcomes: -all : Deny all emails that do not match any mechanism (recommended for strict policies). ~all : Soft fail, where the email is less likely to be accepted but not outright rejected. ?all : Neutral, indicating that the policy is neither positive nor negative. Redirect Mechanism ( redirect ): This mechanism is used to specify a domain that will provide the actual SPF record for authorization. The receiving server will look up the provided domain for the SPF record and use it to evaluate the email. For example: v=spf1 redirect=spf.example.com directs to the SPF record of spf.example.com . Explanation Mechanism ( exp ): This mechanism is used to provide a human-readable explanation for the SPF policy. It's not widely supported and mainly serves as a comment. For example: v=spf1 exp=Explanation for this SPF policy -all . SPF mechanisms are combined to create a comprehensive SPF record that specifies which sources are authorized to send emails on behalf of a domain. It's important to carefully design your SPF policy to ensure legitimate emails are not rejected and unauthorized emails are properly blocked.","title":"Sender Policy Framework"},{"location":"sec/Protocols/TLS/","text":"Transport Layer Security Transport Layer Security (TLS) is a cryptographic protocol designed to provide secure communication over a computer network. It is commonly used to secure data transmission over the internet, ensuring that the information exchanged between a client (like a web browser) and a server (like a web server) remains confidential, integral, and authenticated. TLS works by employing a combination of encryption, authentication, and data integrity mechanisms. Here's a high-level overview of how TLS works: Handshake Protocol When a client initiates a connection to a server using TLS, a handshake protocol is employed to establish the parameters of the encryption and authentication process. This handshake involves the following steps: ClientHello - The client sends a \"ClientHello\" message to the server, which includes the list of cryptographic algorithms and protocols it supports, along with a random value. ServerHello - The server responds with a \"ServerHello\" message, selecting the preferred cryptographic suite from the client's options and providing its own random value. Server Certificate - The server sends its digital certificate, which contains its public key and is signed by a trusted Certificate Authority (CA). Key Exchange - The client generates a pre-master secret, encrypts it with the server's public key from the certificate, and sends it back to the server. Both the client and server then independently derive the same symmetric encryption keys from this pre-master secret. Finished - Both the client and server send \"Finished\" messages, which are encrypted and hashed using the derived keys. This demonstrates that the handshake is complete and both parties are ready to start secure data exchange. Data Exchange After the handshake is successfully completed, the client and server have established shared secret keys for encryption and decryption. All data exchanged between them is encrypted using these keys, making it unreadable to anyone intercepting the communication. Encryption and Decryption TLS supports various encryption algorithms, but one commonly used scheme is the Advanced Encryption Standard (AES). This encryption ensures that data transmitted between the client and server remains confidential. Data Integrity and Authentication TLS also employs mechanisms to ensure that the data has not been tampered with during transmission. This is achieved using hash functions, digital signatures, and HMACs (Hash-based Message Authentication Codes). Certificate Verification During the handshake, the client verifies the authenticity of the server's digital certificate by checking whether it is signed by a trusted CA and that the domain name matches the one it intended to connect to. This prevents man-in-the-middle attacks where an attacker impersonates the server.","title":"TLS"},{"location":"sec/Protocols/TLS/#transport-layer-security","text":"Transport Layer Security (TLS) is a cryptographic protocol designed to provide secure communication over a computer network. It is commonly used to secure data transmission over the internet, ensuring that the information exchanged between a client (like a web browser) and a server (like a web server) remains confidential, integral, and authenticated. TLS works by employing a combination of encryption, authentication, and data integrity mechanisms. Here's a high-level overview of how TLS works: Handshake Protocol When a client initiates a connection to a server using TLS, a handshake protocol is employed to establish the parameters of the encryption and authentication process. This handshake involves the following steps: ClientHello - The client sends a \"ClientHello\" message to the server, which includes the list of cryptographic algorithms and protocols it supports, along with a random value. ServerHello - The server responds with a \"ServerHello\" message, selecting the preferred cryptographic suite from the client's options and providing its own random value. Server Certificate - The server sends its digital certificate, which contains its public key and is signed by a trusted Certificate Authority (CA). Key Exchange - The client generates a pre-master secret, encrypts it with the server's public key from the certificate, and sends it back to the server. Both the client and server then independently derive the same symmetric encryption keys from this pre-master secret. Finished - Both the client and server send \"Finished\" messages, which are encrypted and hashed using the derived keys. This demonstrates that the handshake is complete and both parties are ready to start secure data exchange. Data Exchange After the handshake is successfully completed, the client and server have established shared secret keys for encryption and decryption. All data exchanged between them is encrypted using these keys, making it unreadable to anyone intercepting the communication. Encryption and Decryption TLS supports various encryption algorithms, but one commonly used scheme is the Advanced Encryption Standard (AES). This encryption ensures that data transmitted between the client and server remains confidential. Data Integrity and Authentication TLS also employs mechanisms to ensure that the data has not been tampered with during transmission. This is achieved using hash functions, digital signatures, and HMACs (Hash-based Message Authentication Codes). Certificate Verification During the handshake, the client verifies the authenticity of the server's digital certificate by checking whether it is signed by a trusted CA and that the domain name matches the one it intended to connect to. This prevents man-in-the-middle attacks where an attacker impersonates the server.","title":"Transport Layer Security"},{"location":"sec/Protocols/VPN/","text":"Virtual Private Network A VPN, or Virtual Private Network, is a technology that creates a secure and encrypted connection between your device and a remote server. This connection allows you to access the internet through the remote server's network, effectively masking your true IP address and encrypting your online activities. The main features of a VPN are: Data Encryption: When you connect to a VPN, the data transmitted between your device and the VPN server is encrypted. This encryption helps protect your data from being intercepted and viewed by malicious entities or unauthorized users. IP Address Masking: When you use a VPN, your internet traffic is routed through the VPN server, which means that the websites and online services you access will see the VPN server's IP address instead of your actual IP address. This adds a layer of privacy and anonymity to your online activities. There are several types of VPNs, each with specific use cases and features: Remote Access VPN: This type of VPN allows individuals or employees to securely access a private network from a remote location. It's commonly used by businesses to enable employees to connect to their corporate network from home or other remote locations. Site-to-Site VPN (Intranet VPN): Site-to-Site VPNs are used to connect multiple local networks (like different office locations of a company) securely over the internet. This enables seamless communication and data sharing between these sites as if they were on the same physical network. Client-Based VPN (Software VPN): These are the most common types of VPNs used by individuals. They require software to be installed on your device, allowing you to connect securely to a remote server and access the internet through that server's connection. This is what most people refer to when they talk about using a VPN. Gateway-to-Gateway VPN (Hardware VPN): This type of VPN is established between two physical VPN gateways or routers. It's commonly used by businesses for securely connecting multiple branch offices. Implementation VPNs can be implemented using various protocols and technologies. The implementation method depends on the type of VPN and the specific requirements. Here's an overview: Software Installation: For client-based VPNs, the most common approach is to install VPN software on the user's device. This software establishes a secure connection to a remote VPN server. Users then connect to the internet through this server's connection. Examples of popular VPN software include ExpressVPN, NordVPN, and CyberGhost. VPN Protocols: VPNs use different protocols to establish encrypted connections: OpenVPN: This open-source protocol is known for its flexibility, security, and cross-platform compatibility. It often uses port 1194 for UDP or TCP connections. IPsec: Internet Protocol Security is a suite of protocols that can be used to secure communication at the IP layer. It's often used in combination with L2TP or as part of the newer IKEv2 (Internet Key Exchange version 2) protocol. L2TP (Layer 2 Tunneling Protocol): L2TP provides the tunnel, and it's often combined with IPsec for encryption and authentication. It's commonly used for remote access VPNs. SSTP (Secure Socket Tunneling Protocol): Developed by Microsoft, SSTP uses the SSL/TLS protocol for encryption and is commonly used in Windows environments. WireGuard: A newer protocol known for its simplicity and high performance. It aims to provide strong security while being lightweight. Authentication: VPN implementations often involve user authentication. This ensures that only authorized users can access the VPN. Common methods of authentication include username and password, digital certificates, and two-factor authentication. Encryption: Encryption is a fundamental aspect of VPNs. It ensures that the data transmitted between the user's device and the VPN server remains private and secure. Strong encryption algorithms are used to encrypt and decrypt data within the VPN tunnel. VPN Server Infrastructure: VPN service providers maintain a network of VPN servers in various locations. These servers have dedicated IP addresses and are equipped to handle multiple client connections simultaneously. When a user connects to a VPN, they choose a specific server to connect to. Tunnel Establishment: The VPN client software on the user's device initiates a connection to the chosen VPN server. This involves negotiating the encryption and authentication methods, establishing the VPN tunnel, and creating the necessary encryption keys. Data Routing: Once the VPN tunnel is established, all data traffic between the user's device and the VPN server is encrypted and sent through the tunnel. The VPN server then forwards the encrypted data to its final destination on the internet, effectively masking the user's original IP address. Data Decryption and Forwarding: At the destination, the encrypted data is received by the VPN server, decrypted, and sent to its intended recipient (e.g., a website or online service). The recipient's response is encrypted and sent back through the VPN tunnel to the user's device. Exit Node: In the context of client-based VPNs, the VPN server through which your encrypted data exits to the public internet is often referred to as the \"exit node.\" This is the server's IP address that other online services and websites see, providing a layer of anonymity.","title":"VPN"},{"location":"sec/Protocols/VPN/#virtual-private-network","text":"A VPN, or Virtual Private Network, is a technology that creates a secure and encrypted connection between your device and a remote server. This connection allows you to access the internet through the remote server's network, effectively masking your true IP address and encrypting your online activities. The main features of a VPN are: Data Encryption: When you connect to a VPN, the data transmitted between your device and the VPN server is encrypted. This encryption helps protect your data from being intercepted and viewed by malicious entities or unauthorized users. IP Address Masking: When you use a VPN, your internet traffic is routed through the VPN server, which means that the websites and online services you access will see the VPN server's IP address instead of your actual IP address. This adds a layer of privacy and anonymity to your online activities. There are several types of VPNs, each with specific use cases and features: Remote Access VPN: This type of VPN allows individuals or employees to securely access a private network from a remote location. It's commonly used by businesses to enable employees to connect to their corporate network from home or other remote locations. Site-to-Site VPN (Intranet VPN): Site-to-Site VPNs are used to connect multiple local networks (like different office locations of a company) securely over the internet. This enables seamless communication and data sharing between these sites as if they were on the same physical network. Client-Based VPN (Software VPN): These are the most common types of VPNs used by individuals. They require software to be installed on your device, allowing you to connect securely to a remote server and access the internet through that server's connection. This is what most people refer to when they talk about using a VPN. Gateway-to-Gateway VPN (Hardware VPN): This type of VPN is established between two physical VPN gateways or routers. It's commonly used by businesses for securely connecting multiple branch offices.","title":"Virtual Private Network"},{"location":"sec/Protocols/VPN/#implementation","text":"VPNs can be implemented using various protocols and technologies. The implementation method depends on the type of VPN and the specific requirements. Here's an overview: Software Installation: For client-based VPNs, the most common approach is to install VPN software on the user's device. This software establishes a secure connection to a remote VPN server. Users then connect to the internet through this server's connection. Examples of popular VPN software include ExpressVPN, NordVPN, and CyberGhost. VPN Protocols: VPNs use different protocols to establish encrypted connections: OpenVPN: This open-source protocol is known for its flexibility, security, and cross-platform compatibility. It often uses port 1194 for UDP or TCP connections. IPsec: Internet Protocol Security is a suite of protocols that can be used to secure communication at the IP layer. It's often used in combination with L2TP or as part of the newer IKEv2 (Internet Key Exchange version 2) protocol. L2TP (Layer 2 Tunneling Protocol): L2TP provides the tunnel, and it's often combined with IPsec for encryption and authentication. It's commonly used for remote access VPNs. SSTP (Secure Socket Tunneling Protocol): Developed by Microsoft, SSTP uses the SSL/TLS protocol for encryption and is commonly used in Windows environments. WireGuard: A newer protocol known for its simplicity and high performance. It aims to provide strong security while being lightweight. Authentication: VPN implementations often involve user authentication. This ensures that only authorized users can access the VPN. Common methods of authentication include username and password, digital certificates, and two-factor authentication. Encryption: Encryption is a fundamental aspect of VPNs. It ensures that the data transmitted between the user's device and the VPN server remains private and secure. Strong encryption algorithms are used to encrypt and decrypt data within the VPN tunnel. VPN Server Infrastructure: VPN service providers maintain a network of VPN servers in various locations. These servers have dedicated IP addresses and are equipped to handle multiple client connections simultaneously. When a user connects to a VPN, they choose a specific server to connect to. Tunnel Establishment: The VPN client software on the user's device initiates a connection to the chosen VPN server. This involves negotiating the encryption and authentication methods, establishing the VPN tunnel, and creating the necessary encryption keys. Data Routing: Once the VPN tunnel is established, all data traffic between the user's device and the VPN server is encrypted and sent through the tunnel. The VPN server then forwards the encrypted data to its final destination on the internet, effectively masking the user's original IP address. Data Decryption and Forwarding: At the destination, the encrypted data is received by the VPN server, decrypted, and sent to its intended recipient (e.g., a website or online service). The recipient's response is encrypted and sent back through the VPN tunnel to the user's device. Exit Node: In the context of client-based VPNs, the VPN server through which your encrypted data exits to the public internet is often referred to as the \"exit node.\" This is the server's IP address that other online services and websites see, providing a layer of anonymity.","title":"Implementation"}]}